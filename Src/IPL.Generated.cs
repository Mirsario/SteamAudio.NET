//------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
//------------------------------------------------------------------------------
using System;

namespace SteamAudio
{
    using System.Runtime.InteropServices;
    
    public static partial class IPL
    {
        /// <summary>
        /// Status codes returned by Phonon API functions.
        /// </summary>
        public enum Error : int
        {
            /// <summary>
            /// The operation completed successfully.
            /// </summary>
            Success,
            
            /// <summary>
            /// An unspecified error occurred.
            /// </summary>
            Failure,
            
            /// <summary>
            /// The system ran out of memory.
            /// </summary>
            OutOfMemory,
            
            /// <summary>
            /// An error occurred while initializing an external dependency.
            /// </summary>
            Initialization,
        }
        
        /// <summary>
        /// The type of device to use with OpenCL. The appropriate OpenCL drivers must be installed on the user's system.
        /// Multiple OpenCL drivers may be installed on the same system; in this case the first available driver that
        /// exposes the specified kind of device will be used.
        /// </summary>
        public enum ComputeDeviceType : int
        {
            /// <summary>
            /// Use a CPU device only.
            /// </summary>
            Cpu,
            
            /// <summary>
            /// Use a GPU device only.
            /// </summary>
            Gpu,
            
            /// <summary>
            /// Use either a CPU or GPU device, whichever is listed first by the driver.
            /// </summary>
            Any,
        }
        
        /// <summary>
        /// The ray tracer to use for scene representation and simulation. Phonon lets you choose from multiple ray
        /// tracing implementations, each with different trade-offs. You can also choose to use your own ray tracing
        /// implementation.
        /// </summary>
        public enum SceneType : int
        {
            /// <summary>
            /// Phonon's built-in ray tracer which supports multi-threading.
            /// </summary>
            Phonon,
            
            /// <summary>
            /// The Intel Embree ray tracer. This is a highly-optimized multi-threaded CPU 
            /// implementation, and is likely to be faster than the Phonon ray tracer. However,
            /// Embree support requires a 64-bit CPU, and is not available on Android.
            /// </summary>
            Embree,
            
            /// <summary>
            /// The AMD Radeon Rays ray tracer. This is an OpenCL implementation, and can
            /// use either the CPU or the GPU. If using the GPU, it is likely to be
            /// significantly faster than the Phonon ray tracer. However, on heavy
            /// real-time simulation workloads, it may impact the application's frame rate.
            /// </summary>
            RadeonRays,
            
            /// <summary>
            /// Allows you to specify callbacks to your own ray tracer. Useful if your
            /// application already uses a high-performance ray tracer. This option uses
            /// the least amount of memory at run-time, since it does not have to build
            /// any ray tracing data structures of its own.
            /// </summary>
            Custom,
        }
        
        /// <summary>
        /// The type of simulation to perform. All sound sources must use the same type of simulation; it is not
        /// currently possible to use real-time simulation for some sources and baked data for others.
        /// </summary>
        public enum SimulationType : int
        {
            /// <summary>
            /// Real-time simulation. Sound propagation from all sound sources is
            /// constantly updated in a separate thread, as the player moves and interacts
            /// with the scene. This is a very performance-intensive approach, and requires
            /// the user to have a powerful PC for optimal results. This is also the type
            /// of simulation to choose when generating baked data.
            /// </summary>
            Realtime,
            
            /// <summary>
            /// Simulation using baked data. If baked data has been generated for the scene
            /// and sound sources, simulation will be carried out by looking up information
            /// from the baked data. This approach has much lower CPU usage than real-time
            /// simulation, but at the cost of increased memory usage.
            /// </summary>
            Baked,
        }
        
        /// <summary>
        /// The backend to use for applying convolution effects for sound propagation. Phonon lets you choose from
        /// multiple convolution implementations, with different trade-offs.
        /// </summary>
        public enum ConvolutionType : int
        {
            /// <summary>
            /// Phonon's built-in convolution algorithm. This is a highly optimized,
            /// but single-threaded CPU-based implementation. With this implementation,
            /// there is a significant performance advantage to using
            /// @c ::iplGetMixedEnvironmentalAudio compared to using
            /// @c ::iplGetWetAudioForConvolutionEffect.
            /// </summary>
            Phonon,
            
            /// <summary>
            /// The AMD TrueAudio Next convolution algorithm. This is GPU-based
            /// implementation, that requires an AMD GPU that supports
            /// AMD TrueAudio Next. With this implementation, there is no major
            /// performance advantage to using @c ::iplGetMixedEnvironmentalAudio as compared to using @c ::iplGetWetAudioForConvolutionEffect.
            /// </summary>
            TrueAudioNext,
        }
        
        /// <summary>
        /// Whether the audio buffer is encoded using Ambisonics or not.
        /// </summary>
        public enum ChannelLayoutType : int
        {
            /// <summary>
            /// Indicates that each channel of audio data is intended to be played
            /// back by a single speaker. This corresponds to most multi-speaker mono,
            /// stereo, or surround sound configurations.
            /// </summary>
            Speakers,
            
            /// <summary>
            /// Indicates that each channel of audio data is to be interpreted as a
            /// series of Ambisonics coefficients. Playing back such an audio buffer
            /// requires a software or hardware Ambisonics decoder. Phonon contains a
            /// software Ambisonics decoder.
            /// </summary>
            Ambisonics,
        }
        
        /// <summary>
        /// The type of speaker configuration, for audio formats that are not encoded using Ambisonics.
        /// </summary>
        public enum ChannelLayout : int
        {
            /// <summary>
            /// A single speaker, typically in front of the user.
            /// </summary>
            Mono,
            
            /// <summary>
            /// A pair of speakers, one to the left of the user, and one to the right.
            /// This is also the setting to use when playing audio over headphones.
            /// </summary>
            Stereo,
            
            /// <summary>
            /// Four speakers: front left, front right, back left, and back right.
            /// </summary>
            Quadraphonic,
            
            /// <summary>
            /// Six speakers: front left, front center, front right, back left, back
            /// right, and subwoofer.
            /// </summary>
            FivePointOne,
            
            /// <summary>
            /// Eight speakers: front left, front center, front right, side left, side
            /// right, back left, back right, and subwoofer.
            /// </summary>
            SevenPointOne,
            
            /// <summary>
            /// Lets you specify your own speaker configuration. You can specify any
            /// number of speakers, and set their positions relative to the user. This
            /// is useful if you have a large speaker array, or if you want Phonon to
            /// account for the heights at which the speakers have been installed.
            /// </summary>
            Custom,
        }
        
        /// <summary>
        /// The order in which Ambisonics channels are stored in an audio buffer. Each Ambisonics channel is a series of
        /// coefficients for a corresponding basis function, denoted by
        /// </summary>
        /// <remarks>
        /// @f$  Y_l^m(\theta,\phi) 
        /// @endf$, where@f$ \theta
        /// @endf$and@f$ \phi
        /// @endf$are two angles which pinpoint the source relative to the listener, and@f$ l
        /// @endf$and@f$ m
        /// @endf$are two
        /// two integers which, taken together, identify a single Ambisonics channel. Here,@f$  l \geq 0 
        /// @endf$and@f$  -l \leq m \leq l 
        /// @endf$.There are many different conventions used by the audio engineering community to encode Ambisonics coefficients.
        /// Phonon supports many of them.This enumeration defines the sequence in which Ambisonics channels are stored. Since two integers are needed to
        /// identify an Ambisonics channel, there is more than one way to use a single integer to identify an Ambisonics
        /// channel.
        /// </remarks>
        public enum AmbisonicsOrdering : int
        {
            /// <summary>
            /// Specifies the Furse-Malham (FuMa) channel ordering. This is an
            /// extension of traditional B-format encoding to higher-order
            /// Ambisonics.
            /// </summary>
            FurseMalham,
            
            /// <summary>
            /// Specifies the Ambisonics Channel Number scheme for channel ordering.
            /// This is the new standard adopted by the AmbiX Ambisonics format. The
            /// position of each Ambisonics channel is uniquely calculated as
            /// </summary>
            /// <remarks>
            /// @f$  ACN = l^2 + l + m 
            /// @endf$.
            /// </remarks>
            Acn,
        }
        
        /// <summary>
        /// Normalization conventions for Ambisonics channels. There are a few different ways of normalizing the values of
        /// the Ambisonics channels relative to each other. Phonon supports the most popular ones.
        /// </summary>
        public enum AmbisonicsNormalization : int
        {
            /// <summary>
            /// This is the normalization scheme used in Furse-Malham
            /// higher-order Ambisonics. Each channel is normalized to not
            /// exceed 1.0, and a -3 dB gain correction is applied to
            /// channel 0.
            /// </summary>
            FurseMalham,
            
            /// <summary>
            /// Also called Schmidt semi-normalized form. This is the
            /// normalization scheme used in the AmbiX format.
            /// </summary>
            SN3D,
            
            /// <summary>
            /// This normalization scheme is based on the mathematical
            /// definition of Ambisonics. It is closely related to
            /// @c ::IPL_AMBISONICSNORMALIZATION_SN3D by a series of scaling
            /// factors. This normalization scheme is used internally
            /// throughout Phonon, and using it results in the fastest
            /// performance.
            /// </summary>
            N3D,
        }
        
        /// <summary>
        /// Whether the data is interleaved or deinterleaved.
        /// </summary>
        public enum ChannelOrder : int
        {
            /// <summary>
            /// Sample values for each channel are stored one after another, followed by
            /// the next set of sample values for each channel, etc. In the case of
            /// 2-channel stereo, this would correspond to **LRLRLRLR...**
            /// </summary>
            Interleaved,
            
            /// <summary>
            /// All sample values for the first channel are stored one after another,
            /// followed by the sample values for the next channel, etc. In the case of
            /// 2-channel stereo, this would correspond to **LLLL...RRRR...**
            /// </summary>
            Deinterleaved,
        }
        
        /// <summary>
        /// The type of HRTF database to use for binaural rendering. You can either use the built-in HRTF database, or
        /// supply your own HRTF data at run-time.
        /// </summary>
        public enum HrtfDatabaseType : int
        {
            /// <summary>
            /// The built-in HRTF database.
            /// </summary>
            Default,
            
            /// <summary>
            /// An HRTF database loaded from a SOFA file. SOFA is an AES standard
            /// file format for storing and exchanging acoustic data, including HRTFs.
            /// For more information on the SOFA format, see
            /// https://www.sofaconventions.org/
            /// </summary>
            Sofa,
        }
        
        /// <summary>
        /// Techniques for interpolating HRTF data. This is used when rendering a point source whose position relative to
        /// the listener is not contained in the measured HRTF data used by Phonon.
        /// </summary>
        public enum HrtfInterpolation : int
        {
            /// <summary>
            /// Nearest-neighbor filtering, i.e., no interpolation. Selects the
            /// measurement location that is closest to the source's actual location.
            /// </summary>
            Nearest,
            
            /// <summary>
            /// Bilinear filtering. Incurs a relatively high CPU overhead as compared to
            /// nearest-neighbor filtering, so use this for sounds where it has a
            /// significant benefit.
            /// </summary>
            Bilinear,
        }
        
        /// <summary>
        /// The kind of distance attenuation model to use when calculating frequency-independent distance attenuation
        /// along a path from the source to the listener.
        /// </summary>
        public enum DistanceAttenuationModelType : int
        {
            /// <summary>
            /// The default distance attenuation model. Same as
            /// @c IPL_DISTANCEATTENUATION_INVERSEDISTANCE with
            /// @c minDistance = 1.
            /// </summary>
            Default,
            
            /// <summary>
            /// A physically-based inverse-distance attenuation
            /// model. The attenuated amplitude of a source is
            /// 1 / max(@c distance, @c minDistance), where
            /// @c distance is the length of the path from the
            /// source to the listener, and @c minDistance is a
            /// parameter (see @c IPLDistanceAttenuationModel).
            /// </summary>
            InversedDistance,
            
            /// <summary>
            /// A user-specified distance attenuation model that uses
            /// a callback function whenever the distance attenuation
            /// value needs to be calculated.
            /// </summary>
            Callback,
        }
        
        /// <summary>
        /// The kind of air absorption model to use when calculating frequency-dependent air absorption along a path from 
        /// the source to the listener.
        /// </summary>
        public enum AirAbsorptionModelType : int
        {
            /// <summary>
            /// The default air absorption model. Same as
            /// @c IPL_AIRABSORPTION_EXPONENTIAL with @c coefficients = {0.0002, 0.0017, 
            /// 0.0182}.
            /// </summary>
            Default,
            
            /// <summary>
            /// An exponential decay model for air absorption. The attenuated amplitude of
            /// sound at distance r is exp(-kr), with k being a frequency-dependent
            /// coefficient.
            /// </summary>
            Exponential,
            
            /// <summary>
            /// A user-specified air absorption model that uses a callback function
            /// whenever the air absorption value needs to be calculated.
            /// </summary>
            Callback,
        }
        
        /// <summary>
        /// The algorithm to use when checking for direct path occlusion. Phonon can check whether a direct sound path is
        /// occluded by scene geometry, and optionally how much of a sound source is occluded.
        /// </summary>
        public enum DirectOcclusionMethod : int
        {
            /// <summary>
            /// Performs a rudimentary occlusion test by checking if the ray from the
            /// listener to the source is occluded by any scene geometry. If so, the
            /// sound will be considered to be completely occluded. The Environment
            /// object created by the game engine must have a valid Scene object for
            /// this to work.
            /// </summary>
            Raycast,
            
            /// <summary>
            /// Performs a slightly more complicated occlusion test: the source is
            /// treated as a sphere, and rays are traced from the listener to various
            /// points in the interior of the sphere. The proportion of rays that are
            /// occluded by scene geometry determines the how much of the sound
            /// source is considered occluded. The Environment object created by the 
            /// game engine must have a valid Scene object for this to work.
            /// </summary>
            Volumetric,
        }
        
        /// <summary>
        /// The method to use when rendering occluded or partially occluded sound. Phonon can model sound passing through
        /// solid objects, and optionally apply frequency-dependent transmission filters.
        /// </summary>
        public enum DirectOcclusionMode : int
        {
            /// <summary>
            /// Does not perform any occlusion checks. Sound will be 
            /// audible through solid objects.
            /// </summary>
            None,
            
            /// <summary>
            /// Perform occlusion checks but do not model transmission.
            /// Occluded sound will be completely inaudible.
            /// </summary>
            NoTransmission,
            
            /// <summary>
            /// Perform occlusion checks and model transmission; occluded
            /// sound will be scaled by a frequency-independent
            /// attenuation value. This value is calculated based on the
            /// transmission properties of the object occluding the
            /// direct sound path.
            /// </summary>
            TransmissionByVolume,
            
            /// <summary>
            /// Perform occlusion checks and model transmission; occluded
            /// sound will be rendered with a frequency-dependent
            /// transmission filter. This filter is calculated based on
            /// the transmission properties of the object occluding the
            /// direct sound path.
            /// </summary>
            TransmissionByFrequency,
        }
        
        /// <summary>
        /// Defines how a set of baked data should be interpreted.
        /// </summary>
        public enum BakedDataType : int
        {
            /// <summary>
            /// Baked sound propagation from a static source to a moving listener.
            /// </summary>
            StaticSource,
            
            /// <summary>
            /// Baked sound propagation from a moving source to a static listener.
            /// </summary>
            StaticListener,
            
            /// <summary>
            /// Baked listener-centric reverb.
            /// </summary>
            Reverb,
        }
        
        /// <summary>
        /// The algorithm to use when generating a set of probes. Probes are generated by specifying a bounding box for a
        /// portion of the scene, and an algorithm for filling the volume of the box with probes. You can generate probes
        /// using different algorithms in different portions of a scene. The bounding boxes used for probe generation in
        /// different regions may overlap, although this is not typical.
        /// </summary>
        public enum ProbePlacement : int
        {
            /// <summary>
            /// Places a single probe in the center of the box. The radius of the probe is
            /// large enough to fill the interior of the box.
            /// </summary>
            Centroid,
            
            /// <summary>
            /// Generates probes throughout the volume of the box. The algorithm is adaptive,
            /// and generates more probes in regions of higher geometric complexity, and
            /// fewer probes around empty space. &lt;b&gt;This option is currently not supported&lt;/b&gt;.
            /// </summary>
            Octree,
            
            /// <summary>
            /// Generates probes that are uniformly-spaced, at a fixed height above solid
            /// geometry. A probe will never be generated above another probe unless there is
            /// a solid object between them. The goal is to model floors or terrain, and
            /// generate probes that are a fixed height above the floor or terrain, and
            /// uniformly-spaced along the horizontal plane. This algorithm is not suitable
            /// for scenarios where the listener may fly into a region with no probes;
            /// if this happens, the listener will not be influenced by any of the baked
            /// data.
            /// </summary>
            Uniformfloor,
        }
        
        /// <summary>
        /// A point or vector in 3D space. Phonon uses a right-handed coordinate system, with the positive x-axis pointing
        /// right, the positive y-axis pointing up, and the negative z-axis pointing ahead. Position and direction data
        /// obtained from a game engine or audio engine must be properly transformed before being passed to any Phonon API
        /// function.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct Vector3
        {
            /// <summary>
            /// The x-coordinate.
            /// </summary>
            public float x;
            
            /// <summary>
            /// The y-coordinate.
            /// </summary>
            public float y;
            
            /// <summary>
            /// The z-coordinate.
            /// </summary>
            public float z;
        }
        
        /// <summary>
        /// An axis-aligned box. Axis-aligned boxes are used to specify a volume of 3D space.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct Box
        {
            /// <summary>
            /// The minimum coordinates of any vertex.
            /// </summary>
            public IPL.Vector3 minCoordinates;
            
            /// <summary>
            /// The maximum coordinates of any vertex.
            /// </summary>
            public IPL.Vector3 maxCoordinates;
        }
        
        /// <summary>
        /// A sphere. Spheres are used to define a region of influence around a point.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct Sphere
        {
            /// <summary>
            /// The center.
            /// </summary>
            public IPL.Vector3 center;
            
            /// <summary>
            /// The radius.
            /// </summary>
            public float radius;
        }
        
        /// <summary>
        /// Specifies constraints on the type of OpenCL device to create. This information is intended to be passed to
        /// @c iplCreateComputeDevice.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct ComputeDeviceFilter
        {
            /// <summary>
            /// The type of device to use.
            /// </summary>
            public IPL.ComputeDeviceType type;
            
            /// <summary>
            /// The maximum number of GPU compute units (CUs) that the 
            /// application will reserve on the device. When set to zero, 
            /// resource reservation is disabled and the entire GPU is used.
            /// </summary>
            public int maxCUsToReserve;
            
            /// <summary>
            /// Fraction of maximum reserved CUs that should be used 
            /// for impulse response (IR) update. The IR update includes 
            /// any simulation performed by Radeon Rays to calculate IR and/or
            /// pre-transformation of the IR for convolution with input audio.
            /// The remaining reserved CUs are used for convolution.
            /// Below are typical scenarios:
            /// </summary>
            /// <remarks>
            /// - &lt;b&gt;Using only AMD TrueAudio Next with Steam Audio.&lt;/b&gt;Set @c fractionCUsForIRUpdate to a value greater than 0 and less
            /// than 1 in this case. This ensures that reserved CUs are
            /// available for IR update as well as convolution. For example,
            /// setting @c maxCUsToReserve to 8 and @c fractionCUsForIRUpdate to .5 will use 4 reserved CUs for convolution and 4 reserved
            /// CUs to pre-transform IR calculated on CPU or GPU.- &lt;b&gt;Using AMD TrueAudio Next and AMD Radeon Rays with Steam Audio.&lt;/b&gt;Choosing @c fractionCUsForIRUpdate may require some experimentation 
            /// to utilize reserved CUs optimally. For example, setting
            /// @c maxCUsToReserve to 8 and @c fractionCUsForIRUpdate to .5 will use
            /// 4 reserved CUs for convolution and 4 reserved CUs for IR update.
            /// However, if IR calculation has high latency with these settings, 
            /// you may want to increase @c fractionCUsForIRUpdate to devote
            /// additional reserved CUs for IR update.- &lt;b&gt;Using only AMD Radeon Rays with Steam Audio.&lt;/b&gt;Set @c fractionCUsForIRUpdate to 1 to make sure all the 
            /// reserved CUs are used for calculating IRs using Radeon Rays 
            /// and pre-transforming the calculated IRs.If the number of reserved CUs assigned for convolution or IR
            /// update are 0, then the entire GPU minus the reserved CUs are 
            /// used for the corresponding calculations. For example,
            /// if @c maxCUsToReserve is set to 8 and @c fractionCUsForIRUpdate is set to 0 then all the reserved CUs are used for convolution and
            /// the rest of the GPU is used for IR update.
            /// </remarks>
            public float fractionCUsForIRUpdate;
        }
        
        /// <summary>
        /// Configures the complexity of the simulation. You can fine-tune these values to arrive at a suitable
        /// balance between performance, memory usage, and acoustic detail.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct SimulationSettings
        {
            /// <summary>
            /// The ray tracer to use for simulation.
            /// </summary>
            /// <seealso cref="IPLSceneType."/>
            /// 
            public IPL.SceneType sceneType;
            
            /// <summary>
            /// The maximum number of rays to trace from the listener to a 
            /// source when simulating volumetric occlusion. Increasing this 
            /// number allows increased smoothness of occlusion transitions, 
            /// but also increases memory consumption. Any positive integer 
            /// may be specified, but typical values are in the range of 32 to 
            /// 512.
            /// </summary>
            public int maxNumOcclusionSamples;
            
            /// <summary>
            /// The number of rays to trace from the listener. Increasing this
            /// number increases the accuracy of the simulation, but also
            /// increases CPU usage. Any positive integer may be specified,
            /// but typical values are in the range of 1024 to 131072.
            /// </summary>
            public int numRays;
            
            /// <summary>
            /// The number of directions to consider when a ray bounces off
            /// a diffuse (or partly diffuse) surface. Increasing this number
            /// increases the accuracy of diffuse reflections, and does not
            /// significantly impact CPU usage. Any positive integer may be
            /// specified, but typical values are in the range of 32 to 4096.
            /// </summary>
            public int numDiffuseSamples;
            
            /// <summary>
            /// The maximum number of times any ray can bounce within the scene.
            /// Increasing this number allows the simulation to more accurately
            /// model reverberant spaces, at the cost of increased CPU usage.
            /// Any positive integer may be specified, but typical values are
            /// in the range of 1 to 32.
            /// </summary>
            public int numBounces;
            
            /// <summary>
            /// The number of threads to create for the simulation. The performance
            /// improves linearly with the number of threads upto the number of 
            /// physical cores available on the CPU.
            /// </summary>
            public int numThreads;
            
            /// <summary>
            /// The time delay between a sound being emitted and the last
            /// audible reflection. Echoes and reverberation longer than this
            /// amount will not be modeled by the simulation. Any positive
            /// number may be specified, but typical values are in the range
            /// of 0.5 to 4.0.
            /// </summary>
            public float irDuration;
            
            /// <summary>
            /// The amount of directional detail in the simulation results.
            /// Phonon encodes the simulation results using Ambisonics.
            /// Increasing this number increases the amount of directional
            /// detail in the simulated acoustics, but at the cost of
            /// increased CPU usage and memory consumption. Supported values 
            /// are between 0 and 3.
            /// </summary>
            public int ambisonicsOrder;
            
            /// <summary>
            /// The maximum number of sound sources that can be simulated
            /// and rendered using a Convolution Effect object at any point
            /// in time. If you attempt to create more than this many
            /// Convolution Effect objects, creation will fail. Increasing
            /// this number allows more sound sources to be rendered with
            /// sound propagation effects, but at the cost of increased
            /// memory consumption.
            /// </summary>
            public int maxConvolutionSources;
            
            /// <summary>
            /// The number of probes that should be baked simultaneously.
            /// Only used if @c sceneType is set to 
            /// @c IPL_SCENETYPE_RADEONRAYS, ignored otherwise. Set this to
            /// 1 unless you are creating a Scene for the purposes of
            /// baking indirect sound using @c iplBakeReverb, @c iplBakePropagation, or @c iplBakeStaticListener.
            /// </summary>
            public int bakingBatchSize;
            
            /// <summary>
            /// The minimum distance between a source and a scene surface,
            /// used when calculating the energy received at the surface from
            /// the source during indirect sound simulation. Increasing this
            /// number reduces the loudness of reflections when standing
            /// close to a wall; decreasing this number results in a more
            /// physically realistic model.
            /// </summary>
            public float irradianceMinDistance;
        }
        
        /// <summary>
        /// A triangle in 3D space. Triangles are specified by their three vertices, which are in turn specified using
        /// indices into a vertex array. See iplSetStaticMeshVertices for how to specify the vertex array. Phonon uses
        /// a counter-clockwise winding order. This means that when looking at the triangle such that the normal is
        /// pointing towards you, the vertices are specified in counter-clockwise order.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public unsafe partial struct Triangle
        {
            /// <summary>
            /// Indices of the three vertices of this triangle. Each triangle must be specified
            /// using three vertices; triangle strip or fan representations are not supported.
            /// </summary>
            public fixed int indices[3];
        }
        
        /// <summary>
        /// The acoustic properties of a surface. You can specify the acoustic material properties of each triangle,
        /// although typically many triangles will share a common material. The acoustic material properties are specified
        /// for three frequency bands with center frequencies of 400 Hz, 2.5 KHz, and 15 KHz.
        /// </summary>
        /// <remarks>
        /// Below are the acoustic material properties for a few standard materials.```cpp
        /// {"generic",{0.10f,0.20f,0.30f,0.05f,0.100f,0.050f,0.030f}}
        /// {"brick",{0.03f,0.04f,0.07f,0.05f,0.015f,0.015f,0.015f}}
        /// {"concrete",{0.05f,0.07f,0.08f,0.05f,0.015f,0.002f,0.001f}}
        /// {"ceramic",{0.01f,0.02f,0.02f,0.05f,0.060f,0.044f,0.011f}}
        /// {"gravel",{0.60f,0.70f,0.80f,0.05f,0.031f,0.012f,0.008f}},
        /// {"carpet",{0.24f,0.69f,0.73f,0.05f,0.020f,0.005f,0.003f}}
        /// {"glass",{0.06f,0.03f,0.02f,0.05f,0.060f,0.044f,0.011f}}
        /// {"plaster",{0.12f,0.06f,0.04f,0.05f,0.056f,0.056f,0.004f}}
        /// {"wood",{0.11f,0.07f,0.06f,0.05f,0.070f,0.014f,0.005f}}
        /// {"metal",{0.20f,0.07f,0.06f,0.05f,0.200f,0.025f,0.010f}}
        /// {"rock",{0.13f,0.20f,0.24f,0.05f,0.015f,0.002f,0.001f}}
        /// ```
        /// </remarks>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct Material
        {
            /// <summary>
            /// Fraction of sound energy absorbed at low frequencies. Between 0.0 and
            /// 1.0.
            /// </summary>
            public float lowFreqAbsorption;
            
            /// <summary>
            /// Fraction of sound energy absorbed at middle frequencies. Between 0.0
            /// and 1.0.
            /// </summary>
            public float midFreqAbsorption;
            
            /// <summary>
            /// Fraction of sound energy absorbed at high frequencies. Between 0.0 and
            /// 1.0.
            /// </summary>
            public float highFreqAbsorption;
            
            /// <summary>
            /// Fraction of sound energy that is scattered in a random direction when
            /// it reaches the surface. Between 0.0 and 1.0. A value of 0.0 describes
            /// a smooth surface with mirror-like reflection properties; a value of 1.0
            /// describes rough surface with diffuse reflection properties.
            /// </summary>
            public float scattering;
            
            /// <summary>
            /// Fraction of sound energy transmitted through at low frequencies.
            /// Between 0.0 and 1.0. 
            /// &lt;b&gt;Used only for direct sound occlusion calculations&lt;/b&gt;.
            /// </summary>
            public float lowFreqTransmission;
            
            /// <summary>
            /// Fraction of sound energy transmitted through at middle frequencies. 
            /// Between 0.0 and 1.0.
            /// &lt;b&gt;Used only for direct sound occlusion calculations&lt;/b&gt;.
            /// </summary>
            public float midFreqTransmission;
            
            /// <summary>
            /// Fraction of sound energy transmitted through at high frequencies. 
            /// Between 0.0 and 1.0.
            /// &lt;b&gt;Used only for direct sound occlusion calculations&lt;/b&gt;.
            /// </summary>
            public float highFreqTransmission;
        }
        
        /// <summary>
        /// A 4x4 matrix used to represent an affine transform. The matrix elements are stored in row-major order.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public unsafe partial struct Matrix4x4
        {
            /// <summary>
            /// The elements of the matrix, in row-major order.
            /// </summary>
            public fixed float elements[16];
        }
        
        /// <summary>
        /// Describes various properties of the audio processing pipeline. Many Phonon API objects that are used by the
        /// audio engine need to know how the audio processing pipeline (i.e., your audio engine) applies DSP effects to
        /// audio data. This structure describes the key parameters.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct RenderingSettings
        {
            /// <summary>
            /// The sampling rate (in Hz) of any audio to be processed by Phonon.
            /// *All audio that is passed to Phonon must use the same sampling
            /// rate.** Phonon will output audio at the same sampling rate as its
            /// input; no sampling rate conversion will be performed. Supported
            /// sampling rates are 24000 Hz, 44100 Hz, and 48000 Hz.
            /// </summary>
            public int samplingRate;
            
            /// <summary>
            /// The number of samples in a single frame of audio. The value of
            /// this parameter should be obtained from your audio engine.
            /// </summary>
            public int frameSize;
            
            /// <summary>
            /// The convolution algorithm to use for any Convolution Effect
            /// objects created for this audio processing pipeline.
            /// </summary>
            public IPL.ConvolutionType convolutionType;
        }
        
        /// <summary>
        /// The format of an audio buffer. Whenever you pass audio data to or from Phonon, you must describe the format in
        /// which the audio is encoded. **Phonon only supports uncompressed PCM wave data, stored in 32-bit floating point
        /// format**. However, Phonon supports many different multi-channel and Ambisonics formats, and the
        /// @c IPLAudioFormat tells Phonon how to interpret a buffer of audio data.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct AudioFormat
        {
            /// <summary>
            /// Indicates whether or not the audio should be
            /// interpreted as Ambisonics data.
            /// </summary>
            public IPL.ChannelLayoutType channelLayoutType;
            
            /// <summary>
            /// Specifies the speaker configuration used for
            /// multi-channel, speaker-based audio data. Ignored
            /// if @c channelLayoutType is
            /// @c ::IPL_CHANNELLAYOUTTYPE_AMBISONICS.
            /// </summary>
            public IPL.ChannelLayout channelLayout;
            
            /// <summary>
            /// The number of channels in the audio data. Only
            /// used if @c channelLayoutType is 
            /// @c ::IPL_CHANNELLAYOUTTYPE_SPEAKERS and
            /// @c channelLayout is
            /// @c ::IPL_CHANNELLAYOUT_CUSTOM.
            /// </summary>
            public int numSpeakers;
            
            /// <summary>
            /// An array of @c IPLVector3 objects indicating the
            /// direction of each speaker relative to the user.
            /// Can be @c NULL. Only used if @c channelLayoutType is @c ::IPL_CHANNELLAYOUTTYPE_SPEAKERS and
            /// @c channelLayout is
            /// @c ::IPL_CHANNELLAYOUT_CUSTOM.
            /// </summary>
            public IntPtr speakerDirections;
            
            /// <summary>
            /// The order of Ambisonics to use. Must be between 0
            /// and 3. Ignored if @c channelLayoutType is
            /// @c ::IPL_CHANNELLAYOUTTYPE_SPEAKERS.
            /// </summary>
            public int ambisonicsOrder;
            
            /// <summary>
            /// The ordering of Ambisonics channels within the
            /// data. Ignored if @c channelLayoutType is
            /// @c ::IPL_CHANNELLAYOUTTYPE_SPEAKERS.
            /// </summary>
            public IPL.AmbisonicsOrdering ambisonicsOrdering;
            
            /// <summary>
            /// The normalization scheme used for Ambisonics
            /// data. Ignored if @c channelLayoutType is
            /// @c ::IPL_CHANNELLAYOUTTYPE_SPEAKERS.
            /// </summary>
            public IPL.AmbisonicsNormalization ambisonicsNormalization;
            
            /// <summary>
            /// Whether the audio data is interleaved or
            /// deinterleaved.
            /// </summary>
            public IPL.ChannelOrder channelOrder;
        }
        
        /// <summary>
        /// A buffer containing audio data. All audio data passed to or from Phonon must be packaged in @c IPLAudioBuffer objects, which describe the format and size of the audio data.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct AudioBuffer
        {
            /// <summary>
            /// The format of the audio data.
            /// </summary>
            public IPL.AudioFormat format;
            
            /// <summary>
            /// The number of samples in the audio buffer. The total number of
            /// elements in the audio buffer is equal to @c numSamples *
            /// @c format.numSpeakers.
            /// </summary>
            public int numSamples;
            
            /// <summary>
            /// A pointer to a contiguous block of memory containing interleaved
            /// audio data in the format described by @c format. Can be @c NULL if @c format.channelOrder is @c ::IPL_CHANNELORDER_DEINTERLEAVED.
            /// </summary>
            public IntPtr interleavedBuffer;
            
            /// <summary>
            /// A pointer to an array of pointers, each of which points to a block
            /// of memory containing audio data for a single channel of audio data
            /// in the format described by @c format. In other words,
            /// deinterleaved audio data doesn't have to be stored contiguously
            /// in memory. Can be @c NULL if @c format.channelOrder is
            /// @c ::IPL_CHANNELORDER_INTERLEAVED.
            /// </summary>
            public IntPtr deinterleavedBuffer;
        }
        
        /// <summary>
        /// Parameters used to describe the HRTF database you want to use when creating a Binaural Renderer object.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct HrtfParams
        {
            /// <summary>
            /// Type of HRTF database to use.
            /// </summary>
            public IPL.HrtfDatabaseType type;
            
            /// <summary>
            /// Reserved. Must be NULL.
            /// </summary>
            public IntPtr hrtfData;
            
            /// <summary>
            /// Name of the SOFA file from which to load HRTF data. Can
            /// be a relative or absolute path. Must be a null-terminated
            /// UTF-8 string.
            /// </summary>
            public IntPtr sofaFileName;
        }
        
        /// <summary>
        /// A distance attenuation model for use when calculating frequency-independent distance attenuation along a
        /// path from the source to the listener.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct DistanceAttenuationModel
        {
            /// <summary>
            /// The type of distance attenuation model to use.
            /// </summary>
            public IPL.DistanceAttenuationModelType type;
            
            /// <summary>
            /// The minimum distance parameter for the model. Only
            /// used if @c type is 
            /// @c IPL_DISTANCEATTENUATION_INVERSEDISTANCE.
            /// </summary>
            public float minDistance;
            
            /// <summary>
            /// The callback function to call when evaluating
            /// distance attenuation. Only used if @c type is
            /// @c IPL_DISTANCEATTENUATION_CALLBACK.
            /// </summary>
            public IPL.DistanceAttenuationCallback callback;
            
            /// <summary>
            /// User-specified data that should be passed to the callback 
            /// function when it is called. Use this to pass in any 
            /// source-specific data that must be known to the 
            /// callback function. Only used if @c type is
            /// @c IPL_DISTANCEATTENUATION_CALLBACK.
            /// </summary>
            public IntPtr userData;
            
            /// <summary>
            /// Flag indicating whether @c userData has been changed.
            /// When @c type is set to @c IPL_DISTANCEATTENUATION_CALLBACK, Steam Audio can avoid repeating some calculations
            /// if @c dirty is set to @c false; these calculations are
            /// should only be carried out when @c userData changes,
            /// in which case @c dirty should be set to @c true.
            /// </summary>
            [MarshalAs(UnmanagedType.U4)]
            public bool dirty;
        }
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate float DistanceAttenuationCallback(float distance, IntPtr userData);
        
        /// <summary>
        /// An air absorption model for use when calculating frequency-dependent air absorption along a path from the
        /// source to the listener.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public unsafe partial struct AirAbsorptionModel
        {
            /// <summary>
            /// The type of air absorption model to use.
            /// </summary>
            public IPL.AirAbsorptionModelType type;
            
            /// <summary>
            /// The frequency-dependent exponential decay coefficients.
            /// Only used if @c type is 
            /// @c IPL_AIRABSORPTION_EXPONENTIAL.
            /// </summary>
            public fixed float coefficients[3];
            
            /// <summary>
            /// The callback function to call when evaluating
            /// air absorption. Only used if @c type is
            /// @c IPL_AIRABSORPTION_CALLBACK.
            /// </summary>
            public IPL.AirAbsorptionCallback callback;
            
            /// <summary>
            /// User-specified data that should be passed to the callback 
            /// function when it is called. Use this to pass in any 
            /// source-specific data that must be known to the 
            /// callback function. Only used if @c type is
            /// @c IPL_AIRABSORPTION_CALLBACK.
            /// </summary>
            public IntPtr userData;
            
            /// <summary>
            /// Flag indicating whether @c userData has been changed.
            /// When @c type is set to @c IPL_AIRABSORPTION_CALLBACK, Steam Audio can avoid repeating some calculations
            /// if @c dirty is set to @c false; these calculations are
            /// should only be carried out when @c userData changes,
            /// in which case @c dirty should be set to @c true.
            /// </summary>
            [MarshalAs(UnmanagedType.U4)]
            public bool dirty;
        }
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate float AirAbsorptionCallback(float distance, int band, IntPtr userData);
        
        /// <summary>
        /// Parameters describing a direct sound path. For each frequency band, the attenuation factor applied to the
        /// direct sound path is:
        /// </summary>
        /// <remarks>
        /// distanceAttenuation * airAbsorption * (occlusionFactor + (1 - occlusionFactor) * transmissionFactor)
        /// </remarks>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public unsafe partial struct DirectSoundPath
        {
            /// <summary>
            /// Unit vector from the listener to the source.
            /// </summary>
            public IPL.Vector3 direction;
            
            /// <summary>
            /// Scaling factor to apply to direct sound, that arises due to the
            /// spherical attenuation of sound with distance from the source.
            /// Linear scale from 0.0 to 1.0.
            /// </summary>
            public float distanceAttenuation;
            
            /// <summary>
            /// Scaling factors to apply to direct sound, for low, middle, and high
            /// frequencies, that arise due to the scattering of sound waves as they
            /// travel through the air. Linear scale from 0.0 to 1.0.
            /// </summary>
            public fixed float airAbsorption[3];
            
            /// <summary>
            /// Time delay (in seconds) due to propagation from the source to the
            /// listener.
            /// </summary>
            public float propagationDelay;
            
            /// <summary>
            /// Scaling factor to apply to direct sound, that arises due to occlusion
            /// by scene geometry. Linear scale from 0.0 to 1.0.
            /// </summary>
            public float occlusionFactor;
            
            /// <summary>
            /// Scaling factors to apply to direct sound, for low, middle, and high
            /// frequencies, that arise due to the transmission of sound waves through
            /// scene geometry. Linear scale from 0.0 to 1.0.
            /// </summary>
            public fixed float transmissionFactor[3];
            
            /// <summary>
            /// Scaling factor to apply to direct sound, that arises due to the
            /// directivity pattern of the source. Linear scale from 0.0 to 1.0.
            /// </summary>
            public float directivityFactor;
        }
        
        /// <summary>
        /// Specifies a directivity pattern. A simple weighted dipole pattern may be specified. Alternatively, a callback
        /// may be specified to allow user-provided code to be called whenever the directivity pattern needs to be
        /// evaluated.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct Directivity
        {
            /// <summary>
            /// Controls the blend between a monopole (omnidirectional) and dipole
            /// directivity pattern. 0.0 means pure monopole, 1.0 means pure
            /// dipole. 0.5 results in a cardioid pattern.
            /// </summary>
            public float dipoleWeight;
            
            /// <summary>
            /// Controls the width of the dipole directivity pattern. Higher
            /// values mean sharper, more focused dipoles.
            /// </summary>
            public float dipolePower;
            
            /// <summary>
            /// Pointer to a function to call when the directivity pattern needs
            /// to be evaluated.
            /// </summary>
            public IPL.DirectivityCallback callback;
            
            /// <summary>
            /// User-specified data that should be passed to the callback function
            /// when it is called. Use this to pass in any source-specific
            /// data that must be known to the directivity callback function.
            /// </summary>
            public IntPtr userData;
        }
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate float DirectivityCallback(IPL.Vector3 direction, IntPtr userData);
        
        /// <summary>
        /// Specifies information associated with a sound source.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct Source
        {
            /// <summary>
            /// World-space position of the source.
            /// </summary>
            public IPL.Vector3 position;
            
            /// <summary>
            /// Unit vector pointing forwards from the source.
            /// </summary>
            public IPL.Vector3 ahead;
            
            /// <summary>
            /// Unit vector pointing upwards from the source.
            /// </summary>
            public IPL.Vector3 up;
            
            /// <summary>
            /// Unit vector pointing to the right of the source.
            /// </summary>
            public IPL.Vector3 right;
            
            /// <summary>
            /// The source's directivity pattern.
            /// </summary>
            public IPL.Directivity directivity;
            
            /// <summary>
            /// The source's distance attenuation model.
            /// </summary>
            public IPL.DistanceAttenuationModel distanceAttenuationModel;
            
            /// <summary>
            /// The source's air absorption model.
            /// </summary>
            public IPL.AirAbsorptionModel airAbsorptionModel;
        }
        
        /// <summary>
        /// Flags that specify which parameters from @c IPLDirectSoundPath should be applied by the Direct Sound Effect.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct DirectSoundEffectOptions
        {
            /// <summary>
            /// Whether to apply distance attenuation.
            /// </summary>
            [MarshalAs(UnmanagedType.U4)]
            public bool applyDistanceAttenuation;
            
            /// <summary>
            /// Whether to apply frequency-dependent air absorption.
            /// </summary>
            [MarshalAs(UnmanagedType.U4)]
            public bool applyAirAbsorption;
            
            /// <summary>
            /// Whether to apply source directivity.
            /// </summary>
            [MarshalAs(UnmanagedType.U4)]
            public bool applyDirectivity;
            
            /// <summary>
            /// Whether to apply occlusion and transmission. Also
            /// lets you specify whether to apply frequency-dependent
            /// or frequency-independent transmission.
            /// </summary>
            public IPL.DirectOcclusionMode directOcclusionMode;
        }
        
        /// <summary>
        /// Identifies a set of baked data. It is the application's responsibility to ensure that this data is unique
        /// across the lifetime of an Environment object.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct BakedDataIdentifier
        {
            /// <summary>
            /// 32-bit signed integer that uniquely identifies this set of baked data.
            /// </summary>
            public int identifier;
            
            /// <summary>
            /// How this set of baked data should be interpreted.
            /// </summary>
            public IPL.BakedDataType type;
        }
        
        /// <summary>
        /// Parameters that specify how probes should be created by @c ::iplCreateProbeBox.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct ProbePlacementParams
        {
            /// <summary>
            /// The placement algorithm to use for creating probes.
            /// </summary>
            public IPL.ProbePlacement placement;
            
            /// <summary>
            /// Spacing between probes along the horizontal plane. Only
            /// used if @c placement is @c ::IPL_PLACEMENT_UNIFORMFLOOR.
            /// </summary>
            public float spacing;
            
            /// <summary>
            /// Height of the probes above the closest floor or terrain
            /// surfaces. Only used if @c placement is
            /// @c ::IPL_PLACEMENT_UNIFORMFLOOR.
            /// </summary>
            public float heightAboveFloor;
            
            /// <summary>
            /// The maximum number of triangles to store in an octree leaf
            /// node. Only used if @c placement is @c ::IPL_PLACEMENT_OCTREE.
            /// </summary>
            public int maxOctreeTriangles;
            
            /// <summary>
            /// The maximum depth of the octree. Increasing this value increases
            /// density of the generated probes. Only used if @c placement is
            /// @c ::IPL_PLACEMENT_OCTREE.
            /// </summary>
            public int maxOctreeDepth;
        }
        
        /// <summary>
        /// Specifies the kind of acoustic responses to save in the baked data.
        /// </summary>
        [StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi)]
        public partial struct BakingSettings
        {
            /// <summary>
            /// Enables the generation of I3DL2-compliant parametric reverb. This is most
            /// suited for calculating reverb in relatively enclosed spaces. It is less
            /// suitable for open spaces, or source-to-listener propagation. It consumes
            /// very little memory per probe.
            /// </summary>
            [MarshalAs(UnmanagedType.U4)]
            public bool bakeParametric;
            
            /// <summary>
            /// Enables the generation of detailed impulse responses for convolution reverb.
            /// This is suited for all kinds of spaces, and for reverb as well as
            /// source-to-listener propagation. However, it consumes significantly more
            /// memory per probe.
            /// </summary>
            [MarshalAs(UnmanagedType.U4)]
            public bool bakeConvolution;
            
            /// <summary>
            /// Must be set to the same value as @c irDuration in @c IPLSimulationSettings.
            /// </summary>
            public float irDurationForBake;
        }
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void LogFunction(IntPtr message);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate IntPtr AllocateFunction(ulong arg0, ulong arg1);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void FreeFunction(IntPtr arg0);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void LoadSceneProgressCallback(float progress);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void FinalizeSceneProgressCallback(float progress);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void ClosestHitCallback(ref float origin, ref float direction, float minDistance, float maxDistance, ref float hitDistance, ref float hitNormal, out IntPtr hitMaterial, IntPtr userData);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void AnyHitCallback(ref float origin, ref float direction, float minDistance, float maxDistance, ref int hitExists, IntPtr userData);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void BatchedClosestHitCallback(int numRays, ref IPL.Vector3 origins, ref IPL.Vector3 directions, int rayStride, ref float minDistances, ref float maxDistances, ref float hitDistances, ref IPL.Vector3 hitNormals, out IntPtr hitMaterials, int hitStride, IntPtr userData);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void BatchedAnyHitCallback(int numRays, ref IPL.Vector3 origins, ref IPL.Vector3 directions, int rayStride, ref float minDistances, ref float maxDistances, ref byte hitExists, IntPtr userData);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void SimulationThreadCreateCallback();
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void SimulationThreadDestroyCallback();
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void ProbePlacementProgressCallback(float progress);
        
        [UnmanagedFunctionPointer(CallingConvention.Cdecl)]
        public delegate void BakeProgressCallback(float progress);
        
        /// <summary>
        /// Creates a Context object. A Context object must be created before creating any other API objects.
        /// </summary>
        /// <param name="logCallback">Callback for logging messages. Can be NULL.</param>
        /// <param name="allocateCallback">Callback for allocating memory. Can be NULL.</param>
        /// <param name="freeCallback">Callback for freeing memory. Can be NULL.</param>
        /// <param name="context">[out] Handle to the created Context object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateContext", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateContext(IPL.LogFunction logCallback, IPL.AllocateFunction allocateCallback, IPL.FreeFunction freeCallback, out IntPtr context);
        
        /// <summary>
        /// Destroys a Context object. If any other API objects are still referencing the Context object, it will not be
        /// destroyed; destruction occurs when the Context object's reference count reaches zero.
        /// </summary>
        /// <param name="context">[in, out] Address of a handle to the Context object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyContext", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyContext(ref IntPtr context);
        
        /// <summary>
        /// Performs last-minute cleanup and finalization. This function must be the last API function to be called before
        /// your application exits.
        /// </summary>
        [DllImport(Library, EntryPoint = "iplCleanup", CallingConvention = CallingConvention.Cdecl)]
        public static extern void Cleanup();
        
        /// <summary>
        /// Calculates the relative direction from the listener to a sound source. The returned direction
        /// vector is expressed in the listener's coordinate system.
        /// </summary>
        /// <param name="sourcePosition">World-space coordinates of the source.</param>
        /// <param name="listenerPosition">World-space coordinates of the listener.</param>
        /// <param name="listenerAhead">World-space unit-length vector pointing ahead relative to the listener.</param>
        /// <param name="listenerUp">World-space unit-length vector pointing up relative to the listener.</param>
        /// <returns>A unit-length vector in the listener's coordinate space, pointing from the listener to the source.</returns>
        [DllImport(Library, EntryPoint = "iplCalculateRelativeDirection", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Vector3 CalculateRelativeDirection(IPL.Vector3 sourcePosition, IPL.Vector3 listenerPosition, IPL.Vector3 listenerAhead, IPL.Vector3 listenerUp);
        
        /// <summary>
        /// Creates a Compute Device object. The same Compute Device must be used by the game engine and audio engine
        /// parts of the Phonon integration. Depending on the OpenCL driver and device, this function may take some
        /// time to execute, so do not call it from performance-sensitive code.
        /// </summary>
        /// <param name="context">The Context object used by the game engine.</param>
        /// <param name="deviceFilter">Constraints on the type of device to create.</param>
        /// <param name="device">[out] Handle to the created Compute Device object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateComputeDevice", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateComputeDevice(IntPtr context, IPL.ComputeDeviceFilter deviceFilter, out IntPtr device);
        
        /// <summary>
        /// Destroys a Compute Device object. If any other API objects are still referencing the Compute Device object,
        /// it will not be destroyed; destruction occurs when the object's reference count reaches zero.
        /// </summary>
        /// <param name="device">[in, out] Address of a handle to the Compute Device object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyComputeDevice", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyComputeDevice(ref IntPtr device);
        
        /// <summary>
        /// Creates a Scene object. A Scene object does not store any geometry information on its own; for that you
        /// need to create one or more Static Mesh objects and add them to the Scene object. The Scene object
        /// does contain an array of materials; all triangles in all Static Mesh objects refer to this array in order
        /// to specify their material properties.
        /// </summary>
        /// <param name="context">The Context object used by the game engine.</param>
        /// <param name="computeDevice">Handle to a Compute Device object. Only required if using Radeon Rays for
        /// ray tracing, may be @c NULL otherwise.</param>
        /// <param name="sceneType">The ray tracer to use for scene representation and simulation.</param>
        /// <param name="numMaterials">The number of materials that are used to describe the various surfaces in
        /// the scene. Materials may not be added or removed once the Scene object is
        /// created.</param>
        /// <param name="materials">Array containing all the materials in the Scene object. The number of
        /// @c IPLMaterial objects in the array must be equal to the value of @c numMaterials passed to @c ::iplCreateScene.</param>
        /// <param name="closestHitCallback">Pointer to a function that returns the closest hit along a ray.</param>
        /// <param name="anyHitCallback">Pointer to a function that returns whether a ray hits anything.</param>
        /// <param name="batchedClosestHitCallback">Pointer to a function that returns the closests hits along each ray in a
        /// batch of rays. Can be @c NULL. If not @c NULL, then this function is used
        /// instead of @c closestHitCallback.</param>
        /// <param name="batchedAnyHitCallback">Pointer to a function that returns, for each ray in a batch of rays,
        /// whether the ray hits anything. Can be @c NULL. If not @c NULL, then this
        /// function is used instead of @c anyHitCallback.</param>
        /// <param name="userData">Pointer to a block of memory containing arbitrary data for use
        /// by the closest hit and any hit callbacks.</param>
        /// <param name="scene">[out] Handle to the created Scene object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateScene", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateScene(IntPtr context, IntPtr computeDevice, IPL.SceneType sceneType, int numMaterials, ref IPL.Material materials, IPL.ClosestHitCallback closestHitCallback, IPL.AnyHitCallback anyHitCallback, IPL.BatchedClosestHitCallback batchedClosestHitCallback, IPL.BatchedAnyHitCallback batchedAnyHitCallback, IntPtr userData, out IntPtr scene);
        
        /// <summary>
        /// Destroys a Scene object. If any other API objects are still referencing the Scene object, it will not be
        /// destroyed; destruction occurs when the object's reference count reaches zero.
        /// </summary>
        /// <param name="scene">[in, out] Address of a handle to the Scene object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyScene", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyScene(ref IntPtr scene);
        
        /// <summary>
        /// Creates a Static Mesh object. A Static Mesh object represents a triangle mesh that does not change after it
        /// is created. A Static Mesh object also contains a mapping between each of its triangles and their acoustic
        /// material properties. Static Mesh objects should be used for scene geometry that is guaranteed to never change,
        /// such as rooms, buildings, or triangulated terrain. A Scene object may contain multiple Static Mesh objects,
        /// although typically one is sufficient.
        /// </summary>
        /// <param name="scene">Handle to the Scene object to which to add the Static Mesh object.</param>
        /// <param name="numVertices">Number of vertices in the triangle mesh.</param>
        /// <param name="numTriangles">Number of triangles in the triangle mesh.</param>
        /// <param name="vertices">Array containing the coordinates of all vertices in the Static Mesh object.
        /// The number of @c IPLVector3 objects in the array must be equal to the value of
        /// @c numVertices passed to @c ::iplCreateStaticMesh.</param>
        /// <param name="triangles">Array containing all triangles in the Static Mesh object. The number of
        /// @c IPLTriangle objects in the array must be equal to the value of
        /// @c numTriangles passed to @c ::iplCreateStaticMesh.</param>
        /// <param name="materialIndices">Array containing material indices for all triangles in the Static Mesh object.
        /// The number of material indices in the array must be equal to the value of
        /// @c numTriangles passed to @c ::iplCreateStaticMesh.</param>
        /// <param name="staticMesh">[out] Handle to the created Static Mesh object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateStaticMesh", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateStaticMesh(IntPtr scene, int numVertices, int numTriangles, ref IPL.Vector3 vertices, ref IPL.Triangle triangles, ref int materialIndices, out IntPtr staticMesh);
        
        /// <summary>
        /// Destroys a Static Mesh object. If any other API objects are still referencing the Static Mesh object, it will
        /// not be destroyed; destruction occurs when the object's reference count reaches zero. Since the Scene object
        /// maintains an internal reference to the Static Mesh object, you may call this function at any point after
        /// fully specifying the Static Mesh object using @c ::iplCreateStaticMesh.
        /// </summary>
        /// <param name="staticMesh">[in, out] Address of a handle to the Static Mesh object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyStaticMesh", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyStaticMesh(ref IntPtr staticMesh);
        
        /// <summary>
        /// Serializes a Scene object to a byte array. This function can only be called on a Scene object that
        /// has been created using the Phonon built-in ray tracer.
        /// </summary>
        /// <param name="scene">Handle to the Scene object.</param>
        /// <param name="data">[out] Byte array into which the Scene object will be serialized. It is the
        /// caller's responsibility to manage memory for this array. The array must be large
        /// enough to hold all the data in the Scene object. May be @c NULL, in which case
        /// no data is returned; this is useful when finding out the size of the data stored
        /// in the Scene object.</param>
        [DllImport(Library, EntryPoint = "iplSaveScene", CallingConvention = CallingConvention.Cdecl)]
        public static extern int SaveScene(IntPtr scene, out byte data);
        
        /// <summary>
        /// Creates a Scene object based on data stored in a byte array.
        /// </summary>
        /// <param name="context">The Context object used by the game engine.</param>
        /// <param name="sceneType">The ray tracer to use for scene representation and simulation.</param>
        /// <param name="data">Byte array containing the serialized representation of the Scene object. Must
        /// not be @c NULL.</param>
        /// <param name="size">Size (in bytes) of the serialized data.</param>
        /// <param name="computeDevice">Handle to a Compute Device object. Only required if using Radeon Rays for
        /// ray tracing, may be @c NULL otherwise.</param>
        /// <param name="progressCallback">Pointer to a function that reports the percentage of this function's work
        /// that has been completed. May be @c NULL.</param>
        /// <param name="scene">[out] Handle to the created Scene object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplLoadScene", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error LoadScene(IntPtr context, IPL.SceneType sceneType, ref byte data, int size, IntPtr computeDevice, IPL.LoadSceneProgressCallback progressCallback, out IntPtr scene);
        
        /// <summary>
        /// Saves a Scene object to an OBJ file. An OBJ file is a widely-supported 3D model file format, that can be
        /// displayed using a variety of software on most PC platforms. The OBJ file generated by this function can be
        /// useful for detecting problems that occur when exporting scene data from the game engine to Phonon. 
        /// This function can only be called on a Scene object that has been created using the Phonon built-in ray tracer.
        /// </summary>
        /// <param name="scene">Handle to the Scene object.</param>
        /// <param name="fileBaseName">Absolute or relative path to the OBJ file to generate.</param>
        [DllImport(Library, EntryPoint = "iplSaveSceneAsObj", CallingConvention = CallingConvention.Cdecl)]
        public static extern void SaveSceneAsObj(IntPtr scene, IntPtr fileBaseName);
        
        /// <summary>
        /// Creates an Instanced Mesh object. An Instanced Mesh takes one scene and positions it within another scene.
        /// This is useful if you have the same object, like a pillar, that you want to instantiate multiple times within
        /// the same scene. A scene can be instantiated multiple times within another scene, without incurring any significant
        /// memory overhead. The Instanced Mesh can be moved, rotated, and scaled freely at any time, providing an easy way to
        /// implement dynamic objects whose motion can be described purely in terms of rigid-body transformations.
        /// </summary>
        /// <param name="scene">The scene in which to instantiate another scene.</param>
        /// <param name="instancedScene">The scene to instantiate.</param>
        /// <param name="transform">A transform matrix that maps from the coordinate space of @c instancedScene to the
        /// coordinate space of @c scene. This is used to position and orient @c instancedScene within @c scene. This parameter specifies the initial value of the transform; it can be
        /// freely changed once the Instanced Mesh is created, using 
        /// @c iplUpdateInstancedMeshTransform.</param>
        /// <param name="instancedMesh">[out] Handle to the created Instanced Mesh object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateInstancedMesh", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateInstancedMesh(IntPtr scene, IntPtr instancedScene, IPL.Matrix4x4 transform, out IntPtr instancedMesh);
        
        /// <summary>
        /// Destroys an Instanced Mesh object. If any other API objects are still referencing the Instanced Mesh object,
        /// it will not be destroyed; destruction occurs when the object's reference count reaches zero.
        /// </summary>
        /// <param name="instancedMesh">[in, out] Address of a handle to the Instanced Mesh object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyInstancedMesh", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyInstancedMesh(ref IntPtr instancedMesh);
        
        /// <summary>
        /// Adds an Instanced Mesh object to a Scene object. This function should be called after @c iplCreateInstancedMesh, or
        /// at any point after calling @c iplRemoveInstancedMesh, for the Instanced Mesh to start affecting sound
        /// propagation.
        /// </summary>
        /// <param name="scene">The Scene to which to add the Instanced Mesh. This must be the Scene which was passed
        /// as the @c scene parameter when calling @c iplCreateInstancedMesh to create the
        /// Instanced Mesh.</param>
        /// <param name="instancedMesh">The Instanced Mesh to add to the Scene.</param>
        [DllImport(Library, EntryPoint = "iplAddInstancedMesh", CallingConvention = CallingConvention.Cdecl)]
        public static extern void AddInstancedMesh(IntPtr scene, IntPtr instancedMesh);
        
        /// <summary>
        /// Removes an Instanced Mesh object from a Scene object. After this function is called, the Instanced Mesh will stop
        /// affecting sound propagation, until a subsequent call to @c iplAddInstancedMesh.
        /// </summary>
        /// <param name="scene">The Scene from which to remove the Instanced Mesh.</param>
        /// <param name="instancedMesh">The Instanced Mesh to remove from the Scene.</param>
        [DllImport(Library, EntryPoint = "iplRemoveInstancedMesh", CallingConvention = CallingConvention.Cdecl)]
        public static extern void RemoveInstancedMesh(IntPtr scene, IntPtr instancedMesh);
        
        /// <summary>
        /// Updates the local-to-world transform of an Instanced Mesh within a Scene. This function allows the Instanced
        /// Mesh to be moved, rotated, and scaled dynamically. After calling this function, you must call
        /// @c iplCommitScene for the changes to take effect.
        /// </summary>
        /// <param name="instancedMesh">The Instanced Mesh whose transform is to be updated.</param>
        /// <param name="transform">The new 4x4 transform matrix.</param>
        [DllImport(Library, EntryPoint = "iplUpdateInstancedMeshTransform", CallingConvention = CallingConvention.Cdecl)]
        public static extern void UpdateInstancedMeshTransform(IntPtr instancedMesh, IPL.Matrix4x4 transform);
        
        /// <summary>
        /// Commits a series of changes to Instanced Meshes in a Scene. This function should be called after any calls to
        /// @c iplUpdateInstancedMeshTransform for the changes to take effect. For best performance, call this function after
        /// all transforms have been updated for a given frame.
        /// </summary>
        /// <param name="scene">The Scene to commit changes to.</param>
        [DllImport(Library, EntryPoint = "iplCommitScene", CallingConvention = CallingConvention.Cdecl)]
        public static extern void CommitScene(IntPtr scene);
        
        /// <summary>
        /// Creates an Environment object. It is necessary to call this function even if you are not using the sound
        /// propagation features of Phonon.
        /// </summary>
        /// <param name="context">The Context object used by the game engine.</param>
        /// <param name="computeDevice">Handle to a Compute Device object. Only required if using Radeon Rays for
        /// ray tracing, or if using TrueAudio Next for convolution, may be @c NULL otherwise.</param>
        /// <param name="simulationSettings">The settings to use for simulation. This must be the same settings passed to
        /// @c ::iplCreateScene or @c ::iplLoadScene, whichever was used to create
        /// the Scene object passed in the @c scene parameter to this function.</param>
        /// <param name="scene">The Scene object. May be @c NULL, in which case only direct sound will be 
        /// simulated, without occlusion or any other indirect sound propagation.</param>
        /// <param name="probeManager">The Probe Manager object. May be @c NULL if not using baked data.</param>
        /// <param name="environment">[out] Handle to the created Environment object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateEnvironment", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateEnvironment(IntPtr context, IntPtr computeDevice, IPL.SimulationSettings simulationSettings, IntPtr scene, IntPtr probeManager, out IntPtr environment);
        
        /// <summary>
        /// Destroys an Environment object. If any other API objects are still referencing the Environment object, it will
        /// not be destroyed; destruction occurs when the object's reference count reaches zero.
        /// </summary>
        /// <param name="environment">[in, out] Address of a handle to the Environment object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyEnvironment", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyEnvironment(ref IntPtr environment);
        
        /// <summary>
        /// Sets the number of bounces to use for real-time simulations that use an Environment object. Calling this
        /// function overrides the value of @c bounces set on the @c IPLSimulationSettings structure passed when
        /// calling @c ::iplCreateEnvironment to create this Environment object.
        /// </summary>
        /// <param name="environment">Handle to an Environment object.</param>
        /// <param name="numBounces">The number of bounces to use for all subsequent simulations in the Environment.</param>
        [DllImport(Library, EntryPoint = "iplSetNumBounces", CallingConvention = CallingConvention.Cdecl)]
        public static extern void SetNumBounces(IntPtr environment, int numBounces);
        
        /// <summary>
        /// Mixes a set of audio buffers.  This is primarily useful for mixing the output of multiple Panning Effect
        /// objects, before passing them to a single Virtual Surround Effect or a single Ambisonics Binaural Effect. This
        /// way, applications can significantly accelerate 3D audio rendering for large numbers of sources.
        /// </summary>
        /// <param name="numBuffers">The number of input buffers to mix. Must be greater than 0.</param>
        /// <param name="inputAudio">Array of audio buffers to mix. All of these audio buffers must have identical
        /// formats.</param>
        /// <param name="outputAudio">Audio buffer that will contain the mixed audio data. The format of this buffer
        /// must be identical to all buffers contained in @c inputAudio.</param>
        [DllImport(Library, EntryPoint = "iplMixAudioBuffers", CallingConvention = CallingConvention.Cdecl)]
        public static extern void MixAudioBuffers(int numBuffers, ref IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Interleaves a deinterleaved audio buffer. The formats of @c inputAudio and @c outputAudio must be identical
        /// except for the @c channelOrder field.
        /// </summary>
        /// <param name="inputAudio">The input audio buffer. This audio buffer must be deinterleaved.</param>
        /// <param name="outputAudio">The output audio buffer. This audio buffer must be interleaved.</param>
        [DllImport(Library, EntryPoint = "iplInterleaveAudioBuffer", CallingConvention = CallingConvention.Cdecl)]
        public static extern void InterleaveAudioBuffer(IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Deinterleaves an interleaved audio buffer. The formats of @c inputAudio and @c outputAudio must be identical
        /// except for the @c channelOrder field.
        /// </summary>
        /// <param name="inputAudio">The input audio buffer. This audio buffer must be interleaved.</param>
        /// <param name="outputAudio">The output audio buffer. This audio buffer must be deinterleaved.</param>
        [DllImport(Library, EntryPoint = "iplDeinterleaveAudioBuffer", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DeinterleaveAudioBuffer(IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Converts the format of an audio buffer into the format of the output audio buffer. This is primarily useful
        /// for 360 video and audio authoring workflows. The following format conversions are supported:
        /// </summary>
        /// <param name="inputAudio">The input audio buffer.</param>
        /// <param name="outputAudio">The output audio buffer.</param>
        /// <remarks>
        /// - mono to multi-channel speaker-based formats (stereo, quadraphonic, 5.1, 7.1)
        /// - multi-channel speaker-based (stereo, quadraphonic, 5.1, 7.1) to mono
        /// - stereo to 5.1 or 7.1
        /// - Ambisonics to multi-channel speaker-based (mono, stereo, quadraphonic, 5.1, 7.1)
        /// </remarks>
        [DllImport(Library, EntryPoint = "iplConvertAudioBufferFormat", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ConvertAudioBufferFormat(IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Creates an Ambisonics Rotator object. An Ambisonics Rotator object is used to apply an arbitrary rotation to
        /// audio data encoded in Ambisonics. This is primarily useful in the following situations:
        /// </summary>
        /// <param name="context">The Context object used by the audio engine.</param>
        /// <param name="order">The order of the Ambisonics data to rotate.</param>
        /// <param name="rotator">[out] Handle to the created Ambisonics Rotator object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        /// <remarks>
        /// - If you have an Ambisonics audio buffer whose coefficients are defined relative to world space coordinates,
        /// you can convert them to listener space using an Ambisonics Rotator object. This is necessary when using a
        /// Convolution Effect object, since its output is defined in world space, and will not change if the listener
        /// looks around.- If your final mix is encoded in Ambisonics, and the user is using headphones with head tracking, you can use
        /// the Ambisonics Rotator object to make the sound field stay "in place" as the user looks around in the real
        /// world. This is achieved by using the Ambisonics Rotator object to apply the inverse of the user's rotation
        /// to the final mix.
        /// </remarks>
        [DllImport(Library, EntryPoint = "iplCreateAmbisonicsRotator", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateAmbisonicsRotator(IntPtr context, int order, out IntPtr rotator);
        
        /// <summary>
        /// Destroys an Ambisonics Rotator object.
        /// </summary>
        /// <param name="rotator">[in, out] Address of a handle to the Ambisonics Rotator object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyAmbisonicsRotator", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyAmbisonicsRotator(ref IntPtr rotator);
        
        /// <summary>
        /// Specifies a rotation value. This function must be called before using @c ::iplRotateAmbisonicsAudioBuffer to
        /// rotate an Ambisonics-encoded audio buffer, or the resulting audio will be incorrect.
        /// </summary>
        /// <param name="rotator">Handle to an Ambisonics Rotator object.</param>
        /// <param name="listenerAhead">Unit vector pointing in the direction in which the listener is looking.</param>
        /// <param name="listenerUp">Unit vector pointing upwards from the listener.</param>
        [DllImport(Library, EntryPoint = "iplSetAmbisonicsRotation", CallingConvention = CallingConvention.Cdecl)]
        public static extern void SetAmbisonicsRotation(IntPtr rotator, IPL.Vector3 listenerAhead, IPL.Vector3 listenerUp);
        
        /// <summary>
        /// Rotates an Ambisonics-encoded audio buffer. The @c ::iplSetAmbisonicsRotation function must have been called
        /// prior to calling this function, or the resulting audio will be incorrect. It is possible to pass the same
        /// value for @c inputAudio and @c outputAudio. This results in in-place rotation of the Ambisonics data.
        /// </summary>
        /// <param name="rotator">Handle to an Ambisonics Rotator object.</param>
        /// <param name="inputAudio">Audio buffer containing the Ambisonics-encoded data that is to be rotated. The
        /// format of this buffer must be Ambisonics.</param>
        /// <param name="outputAudio">Audio buffer containing the rotated Ambisonics-encoded data. The format of this
        /// buffer must be Ambisonics.</param>
        [DllImport(Library, EntryPoint = "iplRotateAmbisonicsAudioBuffer", CallingConvention = CallingConvention.Cdecl)]
        public static extern void RotateAmbisonicsAudioBuffer(IntPtr rotator, IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Creates a Binaural Renderer object. This function must be called before creating any Panning Effect objects,
        /// Object-Based Binaural Effect objects, Virtual Surround Effect objects, or Ambisonics Binaural Effect objects.
        /// Calling this function for the first time is somewhat expensive; avoid creating Binaural Renderer objects in
        /// your audio thread if at all possible. **This function is not thread-safe. It cannot be simultaneously called
        /// from multiple threads.**
        /// </summary>
        /// <param name="context">The Context object used by the audio engine.</param>
        /// <param name="renderingSettings">An @c IPLRenderingSettings object describing the audio pipeline's DSP processing
        /// parameters. These properties must remain constant throughout the lifetime of your
        /// application.</param>
        /// <param name="params">Parameters describing the type of HRTF data you wish to use (built-in HRTF data or
        /// your own custom HRTF data).</param>
        /// <param name="renderer">[out] Handle to the created Binaural Renderer object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateBinauralRenderer", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateBinauralRenderer(IntPtr context, IPL.RenderingSettings renderingSettings, IPL.HrtfParams @params, out IntPtr renderer);
        
        /// <summary>
        /// Destroys a Binaural Renderer object. If any other API objects are still referencing the Binaural Renderer
        /// object, it will not be destroyed; destruction occurs when the object's reference count reaches zero.
        /// </summary>
        /// <param name="renderer">[in, out] Address of a handle to the Binaural Renderer object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyBinauralRenderer", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyBinauralRenderer(ref IntPtr renderer);
        
        /// <summary>
        /// Creates a Panning Effect object. This can be used to render a point source on surround speakers, or using
        /// Ambisonics.
        /// </summary>
        /// <param name="renderer">Handle to a Binaural Renderer object.</param>
        /// <param name="inputFormat">The format of the audio buffers that will be passed as input to this effect. All
        /// subsequent calls to @c ::iplApplyPanningEffect for this effect object must use
        /// @c IPLAudioBuffer objects with the same format as specified here. The input format
        /// must not be Ambisonics.</param>
        /// <param name="outputFormat">The format of the audio buffers which will be used to retrieve the output from
        /// this effect. All subsequent calls to @c ::iplApplyPanningEffect for this effect
        /// object must use @c IPLAudioBuffer objects with the same format as specified here.
        /// Any valid audio format may be specified as the output format.</param>
        /// <param name="effect">[out] Handle to the created Panning Effect object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreatePanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreatePanningEffect(IntPtr renderer, IPL.AudioFormat inputFormat, IPL.AudioFormat outputFormat, out IntPtr effect);
        
        /// <summary>
        /// Destroys a Panning Effect object.
        /// </summary>
        /// <param name="effect">[in, out] Address of a handle to the Panning Effect object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyPanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyPanningEffect(ref IntPtr effect);
        
        /// <summary>
        /// Applies 3D panning to a buffer of audio data, using the configuration of a Panning Effect object. The input
        /// audio is treated as emanating from a single point. If the input audio buffer contains more than one channel,
        /// it will automatically be downmixed to mono.
        /// </summary>
        /// <param name="effect">Handle to a Panning Effect object.</param>
        /// <param name="binauralRenderer">Handle to a Binaural Renderer object that should be used to apply the panning
        /// effect.</param>
        /// <param name="inputAudio">Audio buffer containing the data to render using 3D panning. The format of this
        /// buffer must match the @c inputFormat parameter passed to @c ::iplCreatePanningEffect.</param>
        /// <param name="direction">Unit vector from the listener to the point source, relative to the listener's
        /// coordinate system.</param>
        /// <param name="outputAudio">Audio buffer that should contain the rendered audio data. The format of this buffer
        /// must match the @c outputFormat parameter passed to @c ::iplCreatePanningEffect.</param>
        [DllImport(Library, EntryPoint = "iplApplyPanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ApplyPanningEffect(IntPtr effect, IntPtr binauralRenderer, IPL.AudioBuffer inputAudio, IPL.Vector3 direction, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Resets any internal state maintained by a Panning Effect object. This is useful if the Panning Effect object
        /// is going to be disabled/unused for a few frames; resetting the internal state will prevent an audible glitch
        /// when the Panning Effect object is re-enabled at a later time.
        /// </summary>
        /// <param name="effect">Handle to a Panning Effect object.</param>
        [DllImport(Library, EntryPoint = "iplFlushPanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FlushPanningEffect(IntPtr effect);
        
        /// <summary>
        /// Creates an Object-Based Binaural Effect object. This can be used to render a point source using HRTF-based
        /// binaural rendering.
        /// </summary>
        /// <param name="renderer">Handle to a Binaural Renderer object.</param>
        /// <param name="inputFormat">The format of the audio buffers that will be passed as input to this effect. All
        /// subsequent calls to @c ::iplApplyBinauralEffect for this effect object must use
        /// @c IPLAudioBuffer objects with the same format as specified here. The input format
        /// must not be Ambisonics.</param>
        /// <param name="outputFormat">The format of the audio buffers which will be used to retrieve the output from this
        /// effect. All subsequent calls to @c ::iplApplyBinauralEffect for this effect object
        /// must use @c IPLAudioBuffer objects with the same format as specified here. The
        /// output format must be stereo (2 channels).</param>
        /// <param name="effect">[out] Handle to the created Object-Based Binaural Effect object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateBinauralEffect(IntPtr renderer, IPL.AudioFormat inputFormat, IPL.AudioFormat outputFormat, out IntPtr effect);
        
        /// <summary>
        /// Destroys an Object-Based Binaural Effect object.
        /// </summary>
        /// <param name="effect">[in, out] Address of a handle to the Object-Based Binaural Effect object to
        /// destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyBinauralEffect(ref IntPtr effect);
        
        /// <summary>
        /// Applies HRTF-based binaural rendering to a buffer of audio data. The input audio is treated as emanating from
        /// a single point. If the input audio buffer contains more than one channel, it will automatically be downmixed to
        /// mono. Using bilinear interpolation (by setting @c interpolation to @c ::IPL_HRTFINTERPOLATION_BILINEAR) can
        /// incur a relatively high CPU cost. Use it only on sources where nearest-neighbor filtering
        /// (@c ::IPL_HRTFINTERPOLATION_NEAREST) produces suboptimal results. Typically, bilinear filtering is most useful
        /// for wide-band noise-like sounds, such as radio static, mechanical noise, fire, etc.
        /// </summary>
        /// <param name="effect">Handle to an Object-Based Binaural Effect object.</param>
        /// <param name="binauralRenderer">Handle to a Binaural Renderer object that should be used to apply the binaural
        /// effect. Each Binaural Renderer corresponds to an HRTF (which may be loaded from
        /// SOFA files); the value of this parameter determines which HRTF is used to
        /// spatialize the input audio.</param>
        /// <param name="inputAudio">Audio buffer containing the data to render using binaural rendering. The format of
        /// this buffer must match the @c inputFormat parameter passed to
        /// @c ::iplCreateBinauralEffect.</param>
        /// <param name="direction">Unit vector from the listener to the point source, relative to the listener's
        /// coordinate system.</param>
        /// <param name="interpolation">The interpolation technique to use when rendering a point source at a location
        /// that is not contained in the measured HRTF data used by Phonon. **If using a custom
        /// HRTF database, this value must be set to IPL_HRTFINTERPOLATION_BILINEAR.**</param>
        /// <param name="spatialBlend">Amount to blend inputAudio with spatialized audio. When set to 0, outputAudio is not
        /// spatialized at all and is close to inputAudio. If set to 1, outputAudio is fully
        /// spatialized.</param>
        /// <param name="outputAudio">Audio buffer that should contain the rendered audio data. The format of this
        /// buffer must match the @c outputFormat parameter passed to
        /// @c ::iplCreateBinauralEffect.</param>
        [DllImport(Library, EntryPoint = "iplApplyBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ApplyBinauralEffect(IntPtr effect, IntPtr binauralRenderer, IPL.AudioBuffer inputAudio, IPL.Vector3 direction, IPL.HrtfInterpolation interpolation, float spatialBlend, IPL.AudioBuffer outputAudio);
        
        [DllImport(Library, EntryPoint = "iplApplyBinauralEffectWithParameters", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ApplyBinauralEffectWithParameters(IntPtr effect, IntPtr binauralRenderer, IPL.AudioBuffer inputAudio, IPL.Vector3 direction, IPL.HrtfInterpolation interpolation, [MarshalAs(UnmanagedType.U4)] bool enableSpatialBlend, float spatialBlend, IPL.AudioBuffer outputAudio, ref float leftDelay, ref float rightDelay);
        
        /// <summary>
        /// Resets any internal state maintained by an Object-Based Binaural Effect object. This is useful if the 
        /// Object-Based Binaural Effect object is going to be disabled/unused for a few frames; resetting the internal 
        /// state will prevent an audible glitch when the Object-Based Binaural Effect object is re-enabled at a later 
        /// time.
        /// </summary>
        /// <param name="effect">Handle to an Object-Based Binaural Effect object.</param>
        [DllImport(Library, EntryPoint = "iplFlushBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FlushBinauralEffect(IntPtr effect);
        
        /// <summary>
        /// Creates a Virtual Surround Effect object. This can be used to render a multichannel surround sound data using
        /// HRTF-based binaural rendering.
        /// </summary>
        /// <param name="renderer">Handle to a Binaural Renderer object.</param>
        /// <param name="inputFormat">The format of the audio buffers that will be passed as input to this effect. All
        /// subsequent calls to @c ::iplApplyVirtualSurroundEffect for this effect object must
        /// use @c IPLAudioBuffer objects with the same format as specified here. The input
        /// format must not be Ambisonics.</param>
        /// <param name="outputFormat">The format of the audio buffers which will be used to retrieve the output from this
        /// effect. All subsequent calls to @c ::iplApplyVirtualSurroundEffect for this effect
        /// object must use @c IPLAudioBuffer objects with the same format as specified here.
        /// The output format must be stereo (2 channels).</param>
        /// <param name="effect">[out] Handle to the created Virtual Surround Effect object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateVirtualSurroundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateVirtualSurroundEffect(IntPtr renderer, IPL.AudioFormat inputFormat, IPL.AudioFormat outputFormat, out IntPtr effect);
        
        /// <summary>
        /// Destroys a Virtual Surround Effect object.
        /// </summary>
        /// <param name="effect">[in, out] Address of a handle to the Virtual Surround Effect object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyVirtualSurroundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyVirtualSurroundEffect(ref IntPtr effect);
        
        /// <summary>
        /// Applies HRTF-based binaural rendering to a buffer of multichannel audio data.
        /// </summary>
        /// <param name="effect">Handle to a Virtual Surround Effect.</param>
        /// <param name="binauralRenderer">Handle to a Binaural Renderer object that should be used to apply the virtual surround
        /// effect. Each Binaural Renderer corresponds to an HRTF (which may be loaded from
        /// SOFA files); the value of this parameter determines which HRTF is used to
        /// spatialize the input audio.</param>
        /// <param name="inputAudio">Audio buffer containing the data to render using binaural rendering. The format of
        /// this buffer must match the @c inputFormat parameter passed to
        /// @c ::iplCreateVirtualSurroundEffect.</param>
        /// <param name="outputAudio">Audio buffer that should contain the rendered audio data. The format of this buffer
        /// must match the @c outputFormat parameter passed to
        /// @c ::iplCreateVirtualSurroundEffect.</param>
        /// <remarks>
        /// @remark When using a custom HRTF database, calling this function is not supported.
        /// </remarks>
        [DllImport(Library, EntryPoint = "iplApplyVirtualSurroundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ApplyVirtualSurroundEffect(IntPtr effect, IntPtr binauralRenderer, IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Resets any internal state maintained by a Virtual Surround Effect object. This is useful if the Virtual 
        /// Surround Effect object is going to be disabled/unused for a few frames; resetting the internal state will 
        /// prevent an audible glitch when the Virtual Surround Effect object is re-enabled at a later time.
        /// </summary>
        /// <param name="effect">Handle to a Virtual Surround Effect object.</param>
        [DllImport(Library, EntryPoint = "iplFlushVirtualSurroundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FlushVirtualSurroundEffect(IntPtr effect);
        
        /// <summary>
        /// Creates an Ambisonics Panning Effect object. This can be used to render higher-order Ambisonics data using
        /// standard panning algorithms.
        /// </summary>
        /// <param name="renderer">Handle to a Binaural Renderer object.</param>
        /// <param name="inputFormat">The format of the audio buffers that will be passed as input to this effect. All
        /// subsequent calls to @c ::iplApplyAmbisonicsPanningEffect for this effect object must
        /// use @c IPLAudioBuffer objects with the same format as specified here. The input
        /// format must be Ambisonics.</param>
        /// <param name="outputFormat">The format of the audio buffers which will be used to retrieve the output from this
        /// effect. All subsequent calls to @c ::iplApplyAmbisonicsPanningEffect for this
        /// effect object must use @c IPLAudioBuffer objects with the same format as specified
        /// here.</param>
        /// <param name="effect">[out] Handle to the created Ambisonics Panning Effect object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateAmbisonicsPanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateAmbisonicsPanningEffect(IntPtr renderer, IPL.AudioFormat inputFormat, IPL.AudioFormat outputFormat, out IntPtr effect);
        
        /// <summary>
        /// Destroys an Ambisonics Panning Effect object.
        /// </summary>
        /// <param name="effect">[in, out] Address of a handle to the Ambisonics Panning Effect object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyAmbisonicsPanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyAmbisonicsPanningEffect(ref IntPtr effect);
        
        /// <summary>
        /// Applies a panning-based rendering algorithm to a buffer of Ambisonics audio data. Ambisonics encoders and decoders
        /// use many different conventions to store the multiple Ambisonics channels, as well as different normalization
        /// schemes. Make sure that you correctly specify these settings when creating the Ambisonics Panning Effect
        /// object, otherwise the rendered audio will be incorrect.
        /// </summary>
        /// <param name="effect">Handle to an Ambisonics Panning Effect object.</param>
        /// <param name="binauralRenderer">Handle to a Binaural Renderer object that should be used to apply the ambisonics panning
        /// effect.</param>
        /// <param name="inputAudio">Audio buffer containing the data to render. The format of
        /// this buffer must match the @c inputFormat parameter passed to
        /// @c ::iplCreateAmbisonicsPanningEffect.</param>
        /// <param name="outputAudio">Audio buffer that should contain the rendered audio data. The format of this buffer
        /// must match the @c outputFormat parameter passed to
        /// @c ::iplCreateAmbisonicsPanningEffect.</param>
        [DllImport(Library, EntryPoint = "iplApplyAmbisonicsPanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ApplyAmbisonicsPanningEffect(IntPtr effect, IntPtr binauralRenderer, IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Resets any internal state maintained by an Ambisonics Panning Effect object. This is useful if the Ambisonics 
        /// Panning Effect object is going to be disabled/unused for a few frames; resetting the internal state will 
        /// prevent an audible glitch when the Ambisonics Panning Effect object is re-enabled at a later time.
        /// </summary>
        /// <param name="effect">Handle to an Ambisonics Panning Effect object.</param>
        [DllImport(Library, EntryPoint = "iplFlushAmbisonicsPanningEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FlushAmbisonicsPanningEffect(IntPtr effect);
        
        /// <summary>
        /// Creates an Ambisonics Binaural Effect object. This can be used to render higher-order Ambisonics data using
        /// HRTF-based binaural rendering.
        /// </summary>
        /// <param name="renderer">Handle to a Binaural Renderer object.</param>
        /// <param name="inputFormat">The format of the audio buffers that will be passed as input to this effect. All
        /// subsequent calls to @c ::iplApplyAmbisonicsBinauralEffect for this effect object must
        /// use @c IPLAudioBuffer objects with the same format as specified here. The input
        /// format must be Ambisonics.</param>
        /// <param name="outputFormat">The format of the audio buffers which will be used to retrieve the output from this
        /// effect. All subsequent calls to @c ::iplApplyAmbisonicsBinauralEffect for this
        /// effect object must use @c IPLAudioBuffer objects with the same format as specified
        /// here. The output format must be stereo (2 channels).</param>
        /// <param name="effect">[out] Handle to the created Ambisonics Binaural Effect object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateAmbisonicsBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateAmbisonicsBinauralEffect(IntPtr renderer, IPL.AudioFormat inputFormat, IPL.AudioFormat outputFormat, out IntPtr effect);
        
        /// <summary>
        /// Destroys an Ambisonics Binaural Effect object.
        /// </summary>
        /// <param name="effect">[in, out] Address of a handle to the Ambisonics Binaural Effect object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyAmbisonicsBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyAmbisonicsBinauralEffect(ref IntPtr effect);
        
        /// <summary>
        /// Applies HRTF-based binaural rendering to a buffer of Ambisonics audio data. Ambisonics encoders and decoders
        /// use many different conventions to store the multiple Ambisonics channels, as well as different normalization
        /// schemes. Make sure that you correctly specify these settings when creating the Ambisonics Binaural Effect
        /// object, otherwise the rendered audio will be incorrect.
        /// </summary>
        /// <param name="effect">Handle to an Ambisonics Binaural Effect object.</param>
        /// <param name="binauralRenderer">Handle to a Binaural Renderer object that should be used to apply the ambisonics binaural
        /// effect. Each Binaural Renderer corresponds to an HRTF (which may be loaded from
        /// SOFA files); the value of this parameter determines which HRTF is used to
        /// spatialize the input audio.</param>
        /// <param name="inputAudio">Audio buffer containing the data to render using binaural rendering. The format of
        /// this buffer must match the @c inputFormat parameter passed to
        /// @c ::iplCreateAmbisonicsBinauralEffect.</param>
        /// <param name="outputAudio">Audio buffer that should contain the rendered audio data. The format of this buffer
        /// must match the @c outputFormat parameter passed to
        /// @c ::iplCreateAmbisonicsBinauralEffect.</param>
        /// <remarks>
        /// @remark When using a custom HRTF database, calling this function is not supported.
        /// </remarks>
        [DllImport(Library, EntryPoint = "iplApplyAmbisonicsBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ApplyAmbisonicsBinauralEffect(IntPtr effect, IntPtr binauralRenderer, IPL.AudioBuffer inputAudio, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Resets any internal state maintained by an Ambisonics Binaural Effect object. This is useful if the Ambisonics 
        /// Binaural Effect object is going to be disabled/unused for a few frames; resetting the internal state will 
        /// prevent an audible glitch when the Ambisonics Binaural Effect object is re-enabled at a later time.
        /// </summary>
        /// <param name="effect">Handle to an Ambisonics Binaural Effect object.</param>
        [DllImport(Library, EntryPoint = "iplFlushAmbisonicsBinauralEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FlushAmbisonicsBinauralEffect(IntPtr effect);
        
        /// <summary>
        /// Creates an Environmental Renderer object.
        /// </summary>
        /// <param name="context">The Context object used by the audio engine.</param>
        /// <param name="environment">Handle to an Environment object provided by the game engine. It is up to your
        /// application to pass this handle from the game engine to the audio engine.</param>
        /// <param name="renderingSettings">An @c IPLRenderingSettings object describing the audio pipeline's DSP processing
        /// parameters. These properties must remain constant throughout the lifetime of your
        /// application.</param>
        /// <param name="outputFormat">The audio format of the output buffers passed to any subsequent call to
        /// @c ::iplGetMixedEnvironmentalAudio. This format must not be changed once it is set
        /// during the call to this function.</param>
        /// <param name="threadCreateCallback">Pointer to a function that will be called when the internal simulation thread
        /// is created. May be NULL.</param>
        /// <param name="threadDestroyCallback">Pointer to a function that will be called when the internal simulation thread
        /// is destroyed. May be NULL.</param>
        /// <param name="renderer">[out] Handle to the created Environmental Renderer object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateEnvironmentalRenderer", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateEnvironmentalRenderer(IntPtr context, IntPtr environment, IPL.RenderingSettings renderingSettings, IPL.AudioFormat outputFormat, IPL.SimulationThreadCreateCallback threadCreateCallback, IPL.SimulationThreadDestroyCallback threadDestroyCallback, out IntPtr renderer);
        
        /// <summary>
        /// Destroys an Environmental Renderer object. If any other API objects are still referencing the Environmental
        /// Renderer object, the object will not be destroyed; it will only be destroyed once its reference count reaches
        /// zero.
        /// </summary>
        /// <param name="renderer">[in, out] Address of a handle to the Environmental Renderer object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyEnvironmentalRenderer", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyEnvironmentalRenderer(ref IntPtr renderer);
        
        [DllImport(Library, EntryPoint = "iplGetEnvironmentForRenderer", CallingConvention = CallingConvention.Cdecl)]
        public static extern IntPtr GetEnvironmentForRenderer(IntPtr renderer);
        
        /// <summary>
        /// Calculates direct sound path parameters for a single source. It is up to the audio engine to perform audio
        /// processing that uses the information returned by this function.
        /// </summary>
        /// <param name="environment">Handle to an Environment object.</param>
        /// <param name="listenerPosition">World-space position of the listener.</param>
        /// <param name="listenerAhead">Unit vector pointing in the direction in which the listener is looking.</param>
        /// <param name="listenerUp">Unit vector pointing upwards from the listener.</param>
        /// <param name="source">Position, orientation, and directivity of the source.</param>
        /// <param name="sourceRadius">Radius of the sphere defined around the source, for use with
        /// @c ::IPL_DIRECTOCCLUSION_VOLUMETRIC only.</param>
        /// <param name="numSamples">Number of rays to trace, for use with @c ::IPL_DIRECTOCCLUSION_VOLUMETRIC only.
        /// Increasing this value results in smoother occlusion, but also increases CPU cost.
        /// This value must be a positive integer less than the @c maxNumOcclusionSamples value
        /// of the @c IPLSimulationSettings struct passed to @c iplCreateEnvironment.</param>
        /// <param name="occlusionMode">Confuguring the occlusion mode for direct path.</param>
        /// <param name="occlusionMethod">Algorithm to use for checking for direct path occlusion.</param>
        /// <returns>Parameters of the direct path from the source to the listener.</returns>
        [DllImport(Library, EntryPoint = "iplGetDirectSoundPath", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.DirectSoundPath GetDirectSoundPath(IntPtr environment, IPL.Vector3 listenerPosition, IPL.Vector3 listenerAhead, IPL.Vector3 listenerUp, IPL.Source source, float sourceRadius, int numSamples, IPL.DirectOcclusionMode occlusionMode, IPL.DirectOcclusionMethod occlusionMethod);
        
        /// <summary>
        /// Creates a Direct Sound Effect object.
        /// </summary>
        /// <param name="inputFormat">The format of the audio buffers that will be passed as input to this effect. All
        /// subsequent calls to @c ::iplApplyDirectSoundEffect for this effect object must use
        /// @c IPLAudioBuffer objects with the same format as specified here.</param>
        /// <param name="outputFormat">The format of the audio buffers which will be used to retrieve the output from this
        /// effect. All subsequent calls to @c ::iplApplyDirectSoundEffect for this effect 
        /// object must use @c IPLAudioBuffer objects with the same format as specified here.</param>
        /// <param name="renderingSettings">An @c IPLRenderingSettings object describing the audio pipeline's DSP processing
        /// parameters. These properties must remain constant throughout the lifetime of your
        /// application.</param>
        /// <param name="effect">[out] Handle to the created Direct Sound Effect object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateDirectSoundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateDirectSoundEffect(IPL.AudioFormat inputFormat, IPL.AudioFormat outputFormat, IPL.RenderingSettings renderingSettings, out IntPtr effect);
        
        /// <summary>
        /// Destroys a Direct Sound Effect object.
        /// </summary>
        /// <param name="effect">[in, out] Address of a handle to the Direct Sound Effect object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyDirectSoundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyDirectSoundEffect(ref IntPtr effect);
        
        /// <summary>
        /// Applies various parameters in @c IPLDirectSoundPath to a buffer of audio data.
        /// </summary>
        /// <param name="effect">Handle to a Direct Sound Effect object.</param>
        /// <param name="inputAudio">Audio buffer containing the dry audio data. The format of this buffer must match the
        /// @c inputFormat parameter passed to @c ::iplCreateDirectSoundEffect.</param>
        /// <param name="directSoundPath">Parameters of the direct path from the source to the listener.</param>
        /// <param name="options">Specifies which parameters from @c IPLDirectSoundPath should be processed by
        /// the Direct Sound Effect.</param>
        /// <param name="outputAudio">Audio buffer that should contain the wet audio data. The format of this buffer must
        /// match the @c outputFormat parameter passed to @c ::iplCreateDirectSoundEffect.</param>
        [DllImport(Library, EntryPoint = "iplApplyDirectSoundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void ApplyDirectSoundEffect(IntPtr effect, IPL.AudioBuffer inputAudio, IPL.DirectSoundPath directSoundPath, IPL.DirectSoundEffectOptions options, IPL.AudioBuffer outputAudio);
        
        /// <summary>
        /// Resets any internal state maintained by a Direct Sound Effect object. This is useful if the
        /// Direct Sound Effect object is going to be disabled/unused for a few frames; resetting the internal
        /// state will prevent an audible glitch when the Direct Sound Effect object is re-enabled at a later
        /// time.
        /// </summary>
        /// <param name="effect">Handle to a Direct Sound Effect object.</param>
        [DllImport(Library, EntryPoint = "iplFlushDirectSoundEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FlushDirectSoundEffect(IntPtr effect);
        
        /// <summary>
        /// Creates a Convolution Effect object.
        /// </summary>
        /// <param name="renderer">Handle to an Environmental Renderer object.</param>
        /// <param name="identifier">Unique identifier of the corresponding source, as defined in the baked data 
        /// exported by the game engine. Each Convolution Effect object may have an identifier,
        /// which is used only if the Environment object provided by the game engine uses baked
        /// data for sound propagation. If so, the identifier of the Convolution Effect is used
        /// to look up the appropriate information from the baked data. Multiple Convolution
        /// Effect objects may be created with the same identifier; in that case they will use
        /// the same baked data.</param>
        /// <param name="simulationType">Whether this Convolution Effect object should use baked data or real-time simulation.</param>
        /// <param name="inputFormat">Format of all audio buffers passed as input to
        /// @c ::iplSetDryAudioForConvolutionEffect.</param>
        /// <param name="outputFormat">Format of all output audio buffers passed to @c ::iplGetWetAudioForConvolutionEffect.</param>
        /// <param name="effect">[out] Handle to the created Convolution Effect object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateConvolutionEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateConvolutionEffect(IntPtr renderer, IPL.BakedDataIdentifier identifier, IPL.SimulationType simulationType, IPL.AudioFormat inputFormat, IPL.AudioFormat outputFormat, out IntPtr effect);
        
        /// <summary>
        /// Destroys a Convolution Effect object.
        /// </summary>
        /// <param name="effect">[in, out] Address of a handle to the Convolution Effect object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyConvolutionEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyConvolutionEffect(ref IntPtr effect);
        
        /// <summary>
        /// Changes the identifier associated with a Convolution Effect object. This is useful when using a static listener
        /// bake, where you may want to teleport the listener between two or more locations for which baked data has
        /// been generated.
        /// </summary>
        /// <param name="effect">Handle to a Convolution Effect object.</param>
        /// <param name="identifier">The new identifier of the Convolution Effect object.</param>
        [DllImport(Library, EntryPoint = "iplSetConvolutionEffectIdentifier", CallingConvention = CallingConvention.Cdecl)]
        public static extern void SetConvolutionEffectIdentifier(IntPtr effect, IPL.BakedDataIdentifier identifier);
        
        /// <summary>
        /// Specifies a frame of dry audio for a Convolution Effect object. This is the audio data to which sound
        /// propagation effects should be applied.
        /// </summary>
        /// <param name="effect">Handle to a Convolution Effect object.</param>
        /// <param name="source">Position, orientation, and directivity of the sound source emitting the dry audio.</param>
        /// <param name="dryAudio">Audio buffer containing the dry audio data.</param>
        [DllImport(Library, EntryPoint = "iplSetDryAudioForConvolutionEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void SetDryAudioForConvolutionEffect(IntPtr effect, IPL.Source source, IPL.AudioBuffer dryAudio);
        
        /// <summary>
        /// Retrieves a frame of wet audio from a Convolution Effect object. This is the result of applying sound
        /// propagation effects to the dry audio previously specified using @c ::iplSetDryAudioForConvolutionEffect.
        /// </summary>
        /// <param name="effect">Handle to a Convolution Effect object.</param>
        /// <param name="listenerPosition">World-space position of the listener.</param>
        /// <param name="listenerAhead">Unit vector in the direction in which the listener is looking.</param>
        /// <param name="listenerUp">Unit vector pointing upwards from the listener.</param>
        /// <param name="wetAudio">Audio buffer which will be populated with the wet audio data.</param>
        [DllImport(Library, EntryPoint = "iplGetWetAudioForConvolutionEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void GetWetAudioForConvolutionEffect(IntPtr effect, IPL.Vector3 listenerPosition, IPL.Vector3 listenerAhead, IPL.Vector3 listenerUp, IPL.AudioBuffer wetAudio);
        
        /// <summary>
        /// Retrieves a mixed frame of wet audio. This is the sum of all wet audio data from all Convolution Effect
        /// objects that were created using the given Environmental Renderer object. Unless using TrueAudio Next for
        /// convolution, this is likely to provide a significant performance boost to the audio thread as compared to
        /// calling @c ::iplGetWetAudioForConvolutionEffect for each Convolution Effect separately. On the other hand, doing
        /// so makes it impossible to apply additional DSP effects for specific sources before mixing.
        /// </summary>
        /// <param name="renderer">Handle to an Environmental Renderer object.</param>
        /// <param name="listenerPosition">World-space position of the listener.</param>
        /// <param name="listenerAhead">Unit vector in the direction in which the listener is looking.</param>
        /// <param name="listenerUp">Unit vector pointing upwards from the listener.</param>
        /// <param name="mixedWetAudio">Audio buffer which will be populated with the wet audio data.</param>
        [DllImport(Library, EntryPoint = "iplGetMixedEnvironmentalAudio", CallingConvention = CallingConvention.Cdecl)]
        public static extern void GetMixedEnvironmentalAudio(IntPtr renderer, IPL.Vector3 listenerPosition, IPL.Vector3 listenerAhead, IPL.Vector3 listenerUp, IPL.AudioBuffer mixedWetAudio);
        
        /// <summary>
        /// Resets any internal state maintained by a Convolution Effect object. This is useful if the Convolution Effect 
        /// object is going to be disabled/unused for a few frames; resetting the internal state will prevent an audible 
        /// glitch when the Convolution Effect object is re-enabled at a later time.
        /// </summary>
        /// <param name="effect">Handle to a Convolution Effect object.</param>
        [DllImport(Library, EntryPoint = "iplFlushConvolutionEffect", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FlushConvolutionEffect(IntPtr effect);
        
        /// <summary>
        /// Generates probes within a box. This function should typically be called from the game engine's editor, in
        /// response to the user indicating that they want to generate probes in the scene.
        /// </summary>
        /// <param name="context">Handle to the Context object used by the game engine.</param>
        /// <param name="scene">Handle to the Scene object.</param>
        /// <param name="boxLocalToWorldTransform">4x4 local to world transform matrix laid out in column-major format.</param>
        /// <param name="placementParams">Parameters specifying how probes should be generated.</param>
        /// <param name="progressCallback">Pointer to a function that reports the percentage of this function's 
        /// work that has been completed. May be @c NULL.</param>
        /// <param name="probeBox">[out] Handle to the created Probe Box object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateProbeBox", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateProbeBox(IntPtr context, IntPtr scene, ref float boxLocalToWorldTransform, IPL.ProbePlacementParams placementParams, IPL.ProbePlacementProgressCallback progressCallback, out IntPtr probeBox);
        
        /// <summary>
        /// Destroys a Probe Box object.
        /// </summary>
        /// <param name="probeBox">[in, out] Address of a handle to the Probe Box object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyProbeBox", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyProbeBox(ref IntPtr probeBox);
        
        /// <summary>
        /// Retrieves spheres describing the positions and influence radii of all probes in the Probe Box object. This
        /// function should typically be called from the game engine's editor, and the retrieved spheres should be used
        /// for visualization.
        /// </summary>
        /// <param name="probeBox">Handle to a Probe Box object.</param>
        /// <param name="probeSpheres">[out] Array into which information about the probe spheres is returned. It is the
        /// the caller's responsibility to manage memory for this array. The array must be
        /// large enough to hold all the spheres in the Probe Box object. May be @c NULL, in
        /// which case no spheres are returned; this is useful when finding out the number of
        /// probes in the Probe Box object.</param>
        /// <returns>The number of probes in the Probe Box object.</returns>
        [DllImport(Library, EntryPoint = "iplGetProbeSpheres", CallingConvention = CallingConvention.Cdecl)]
        public static extern int GetProbeSpheres(IntPtr probeBox, out IPL.Sphere probeSpheres);
        
        /// <summary>
        /// Serializes a Probe Box object to a byte array. This is typically called by the game engine's editor in order
        /// to save the Probe Box object's data to disk.
        /// </summary>
        /// <param name="probeBox">Handle to a Probe Box object.</param>
        /// <param name="data">[out] Byte array into which the Probe Box object will be serialized. It is the
        /// caller's responsibility to manage memory for this array. The array must be large
        /// enough to hold all the data in the Probe Box object. May be @c NULL, in which case
        /// no data is returned; this is useful when finding out the size of the data stored
        /// in the Probe Box object.</param>
        /// <returns>Size (in bytes) of the serialized data.</returns>
        [DllImport(Library, EntryPoint = "iplSaveProbeBox", CallingConvention = CallingConvention.Cdecl)]
        public static extern int SaveProbeBox(IntPtr probeBox, out byte data);
        
        /// <summary>
        /// Deserializes a Probe Box object from a byte array. This is typically called by the game engine's editor when
        /// loading a Probe Box object from disk.
        /// </summary>
        /// <param name="context">Handle to the Context object used by the game engine.</param>
        /// <param name="data">Byte array containing the serialized representation of the Probe Box object. Must
        /// not be @c NULL.</param>
        /// <param name="size">Size (in bytes) of the serialized data.</param>
        /// <param name="probeBox">[out] Handle to the created Probe Box object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplLoadProbeBox", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error LoadProbeBox(IntPtr context, ref byte data, int size, out IntPtr probeBox);
        
        /// <summary>
        /// Creates a Probe Batch object. A Probe Batch object represents a set of probes that are loaded and unloaded
        /// from memory as a unit when the game is played. A Probe Batch may contain probes from multiple Probe Boxes;
        /// multiple Probe Batches may contain probes from the same Probe Box. At run-time, Phonon does not use Probe
        /// Boxes, it only needs Probe Batches. The typical workflow is as follows:
        /// </summary>
        /// <param name="context">Handle to the Context object used by the game engine.</param>
        /// <param name="probeBatch">[out] Handle to the created Probe Batch object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        /// <remarks>
        /// 1.  Using the editor, the designer creates Probe Boxes to sample the scene.
        /// 2.  Using the editor, the designer specifies Probe Batches, and decides which probes are part of each Probe
        /// Batch.
        /// 3.  The editor saves the Probe Batches along with the rest of the scene data for use at run-time.
        /// 4.  At run-time, Phonon uses the Probe Batches to retrieve baked data.
        /// </remarks>
        [DllImport(Library, EntryPoint = "iplCreateProbeBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateProbeBatch(IntPtr context, out IntPtr probeBatch);
        
        /// <summary>
        /// Destroys a Probe Batch object.
        /// </summary>
        /// <param name="probeBatch">[in, out] Address of a handle to the Probe Batch object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyProbeBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyProbeBatch(ref IntPtr probeBatch);
        
        /// <summary>
        /// Adds a specific probe from a Probe Box to a Probe Batch. Once all probes in a Probe Box have been assigned to
        /// their respective Probe Batches, you can destroy the Probe Box object; the baked data for the probes will
        /// be retained by the Probe Batch.
        /// </summary>
        /// <param name="probeBatch">Handle to a Probe Batch object into which the probe should be added.</param>
        /// <param name="probeBox">Handle to a Probe Box object from which the probe should be added.</param>
        /// <param name="probeIndex">Index of the probe to add. The index is defined relative to the array of probes
        /// returned by @c ::iplGetProbeSpheres.</param>
        [DllImport(Library, EntryPoint = "iplAddProbeToBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern void AddProbeToBatch(IntPtr probeBatch, IntPtr probeBox, int probeIndex);
        
        /// <summary>
        /// Finalizes the set of probes that comprise a Probe Batch. Calling this function builds internal data
        /// structures that are used to rapidly determine which probes influence any given point in 3D space. You may
        /// not call @c ::iplAddProbeToBatch after calling this function. You must call this function before calling
        /// @c ::iplAddProbeBatch to add this Probe Batch object to a Probe Manager object.
        /// </summary>
        /// <param name="probeBatch">Handle to a ProbeBatch object.</param>
        [DllImport(Library, EntryPoint = "iplFinalizeProbeBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern void FinalizeProbeBatch(IntPtr probeBatch);
        
        /// <summary>
        /// Serializes a Probe Batch object to a byte array. This is typically called by the game engine's editor in order
        /// to save the Probe Batch object's data to disk.
        /// </summary>
        /// <param name="probeBatch">Handle to a Probe Batch object.</param>
        /// <param name="data">[out] Byte array into which the Probe Batch object will be serialized. It is the
        /// caller's responsibility to manage memory for this array. The array must be large
        /// enough to hold all the data in the Probe Batch object. May be @c NULL, in which
        /// case no data is returned; this is useful when finding out the size of the data
        /// stored in the Probe Batch object.</param>
        /// <returns>Size (in bytes) of the serialized data.</returns>
        [DllImport(Library, EntryPoint = "iplSaveProbeBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern int SaveProbeBatch(IntPtr probeBatch, out byte data);
        
        /// <summary>
        /// Deserializes a Probe Batch object from a byte array. This is typically called by the game engine's editor when
        /// loading a Probe Batch object from disk. Calling this function implicitly calls @c ::iplFinalizeProbeBatch, so
        /// you do not need to call it explicitly.
        /// </summary>
        /// <param name="context">Handle to the Context object used by the game engine.</param>
        /// <param name="data">Byte array containing the serialized representation of the Probe Batch object. Must
        /// not be @c NULL.</param>
        /// <param name="size">Size (in bytes) of the serialized data.</param>
        /// <param name="probeBatch">[out] Handle to the created Probe Batch object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplLoadProbeBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error LoadProbeBatch(IntPtr context, ref byte data, int size, out IntPtr probeBatch);
        
        /// <summary>
        /// Creates a Probe Manager object. A Probe Manager object manages a set of Probe Batch objects are runtime.
        /// It is typically exported from the game engine to the audio engine via an Environment object. Probe Batch
        /// objects can be dynamically added to or removed from a Probe Manager object.
        /// </summary>
        /// <param name="context">Handle to the Context object used by the game engine.</param>
        /// <param name="probeManager">[out] Handle to the created Probe Manager object.</param>
        /// <returns>Status code indicating whether or not the operation succeeded.</returns>
        [DllImport(Library, EntryPoint = "iplCreateProbeManager", CallingConvention = CallingConvention.Cdecl)]
        public static extern IPL.Error CreateProbeManager(IntPtr context, out IntPtr probeManager);
        
        /// <summary>
        /// Destroys a Probe Manager object.
        /// </summary>
        /// <param name="probeManager">[in, out] Address of a handle to the Probe Manager object to destroy.</param>
        [DllImport(Library, EntryPoint = "iplDestroyProbeManager", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DestroyProbeManager(ref IntPtr probeManager);
        
        /// <summary>
        /// Adds a Probe Batch to a Probe Manager object. Once this function returns, probes in the Probe Batch will be
        /// used to calculate sound propagation effects.
        /// </summary>
        /// <param name="probeManager">Handle to a Probe Manager object.</param>
        /// <param name="probeBatch">Handle to the Probe Batch object to add.</param>
        [DllImport(Library, EntryPoint = "iplAddProbeBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern void AddProbeBatch(IntPtr probeManager, IntPtr probeBatch);
        
        /// <summary>
        /// Removes a Probe Batch from a Probe Manager object. Once this function returns, probes in the Probe Batch will
        /// no longer be used to calculate sound propagation effects.
        /// </summary>
        /// <param name="probeManager">Handle to a Probe Manager object.</param>
        /// <param name="probeBatch">Handle to the Probe Batch object to remove.</param>
        [DllImport(Library, EntryPoint = "iplRemoveProbeBatch", CallingConvention = CallingConvention.Cdecl)]
        public static extern void RemoveProbeBatch(IntPtr probeManager, IntPtr probeBatch);
        
        /// <summary>
        /// Bakes reverb at all probes in a Probe Box. Phonon defines reverb as the indirect sound received at a probe
        /// when a source is placed at the probe's location. This is a time-consuming operation, and should typically be
        /// called from the game engine's editor. The @c numThreads set on the @c IPLSimulationSettings structure passed 
        /// when calling @c ::iplCreateEnvironment to create the Environment object are used for multi-threaded baking.
        /// </summary>
        /// <param name="environment">Handle to an Environment object.</param>
        /// <param name="probeBox">Handle to the Probe Box containing the probes for which to bake reverb.</param>
        /// <param name="bakingSettings">The kind of acoustic responses to bake.</param>
        /// <param name="progressCallback">Pointer to a function that reports the percentage of this function's work that
        /// has been completed. May be @c NULL.</param>
        [DllImport(Library, EntryPoint = "iplBakeReverb", CallingConvention = CallingConvention.Cdecl)]
        public static extern void BakeReverb(IntPtr environment, IntPtr probeBox, IPL.BakingSettings bakingSettings, IPL.BakeProgressCallback progressCallback);
        
        /// <summary>
        /// Bakes propagation effects from a specified source to all probes in a Probe Box. Sources are defined in terms
        /// of a position and a sphere of influence; all probes in the Probe Box that lie within the sphere of influence
        /// are processed by this function. This is a time-consuming operation, and should typically be called from the
        /// game engine's editor. The @c numThreads set on the @c IPLSimulationSettings structure passed when calling 
        /// @c ::iplCreateEnvironment to create the Environment object are used for multi-threaded baking.
        /// </summary>
        /// <param name="environment">Handle to an Environment object.</param>
        /// <param name="probeBox">Handle to the Probe Box containing the probes for which to bake reverb.</param>
        /// <param name="sourceInfluence">Sphere defined by the source position (at its center) and its radius of
        /// influence.</param>
        /// <param name="sourceIdentifier">Identifier of the source. At run-time, a Convolution Effect object can use this
        /// identifier to look up the correct impulse response information.</param>
        /// <param name="bakingSettings">The kind of acoustic responses to bake.</param>
        /// <param name="progressCallback">Pointer to a function that reports the percentage of this function's work that
        /// has been completed. May be @c NULL.</param>
        [DllImport(Library, EntryPoint = "iplBakePropagation", CallingConvention = CallingConvention.Cdecl)]
        public static extern void BakePropagation(IntPtr environment, IntPtr probeBox, IPL.Sphere sourceInfluence, IPL.BakedDataIdentifier sourceIdentifier, IPL.BakingSettings bakingSettings, IPL.BakeProgressCallback progressCallback);
        
        /// <summary>
        /// Bakes propagation effects from all probes in a Probe Box to a specified listener. Listeners are defined
        /// solely by their position; their orientation may freely change at run-time. This is a time-consuming
        /// operation, and should typically be called from the game engine's editor. The @c numThreads set on the 
        /// @c IPLSimulationSettings structure passed when calling @c ::iplCreateEnvironment to create the Environment 
        /// object are used for multi-threaded baking.
        /// </summary>
        /// <param name="environment">Handle to an Environment object.</param>
        /// <param name="probeBox">Handle to the Probe Box containing the probes for which to bake reverb.</param>
        /// <param name="listenerInfluence">Position and influence radius of the listener.</param>
        /// <param name="listenerIdentifier">Identifier of the listener. At run-time, a Convolution Effect object can use this
        /// identifier to look up the correct impulse response information.</param>
        /// <param name="bakingSettings">The kind of acoustic responses to bake.</param>
        /// <param name="progressCallback">Pointer to a function that reports the percentage of this function's work that
        /// has been completed. May be @c NULL.</param>
        [DllImport(Library, EntryPoint = "iplBakeStaticListener", CallingConvention = CallingConvention.Cdecl)]
        public static extern void BakeStaticListener(IntPtr environment, IntPtr probeBox, IPL.Sphere listenerInfluence, IPL.BakedDataIdentifier listenerIdentifier, IPL.BakingSettings bakingSettings, IPL.BakeProgressCallback progressCallback);
        
        /// <summary>
        /// Cancels any bake operations that may be in progress. Typically, an application will call @c ::iplBakeReverb or @c ::iplBakePropagation in a separate thread from the editor's GUI thread, to keep the GUI responsive.
        /// This function can be called from the GUI thread to safely and prematurely terminate execution of any
        /// of these functions.
        /// </summary>
        [DllImport(Library, EntryPoint = "iplCancelBake", CallingConvention = CallingConvention.Cdecl)]
        public static extern void CancelBake();
        
        /// <summary>
        /// Deletes all baked data in a Probe Box that is associated with a given source. If no such baked data
        /// exists, this function does nothing.
        /// </summary>
        /// <param name="probeBox">Handle to a Probe Box object.</param>
        /// <param name="identifier">Identifier of the source whose baked data is to be deleted.</param>
        [DllImport(Library, EntryPoint = "iplDeleteBakedDataByIdentifier", CallingConvention = CallingConvention.Cdecl)]
        public static extern void DeleteBakedDataByIdentifier(IntPtr probeBox, IPL.BakedDataIdentifier identifier);
        
        /// <summary>
        /// Returns the size (in bytes) of the baked data stored in a Probe Box corresponding to a given source.
        /// This is useful for displaying statistics in the editor's GUI.
        /// </summary>
        /// <param name="probeBox">Handle to a Probe Box object.</param>
        /// <param name="identifier">Identifier of the source whose baked data size is to be returned.</param>
        /// <returns>Size (in bytes) of the baked data stored in the Probe Box corresponding to the source.</returns>
        [DllImport(Library, EntryPoint = "iplGetBakedDataSizeByIdentifier", CallingConvention = CallingConvention.Cdecl)]
        public static extern int GetBakedDataSizeByIdentifier(IntPtr probeBox, IPL.BakedDataIdentifier identifier);
    }
}
